{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Project Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNu1sZvo6YeOJNu0oa4WQx2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manu-Gr/NLP-Project---Text-Summarization/blob/main/NLP_Project_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Necessary Libraries"
      ],
      "metadata": {
        "id": "jnu-OVCByyj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "2y-0AS6uzALT"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('automate the boring stuff with python automate the boring stuff with python ( PDFDrive ).pdf','rb')"
      ],
      "metadata": {
        "id": "2995gEUg6GgC"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrEGS32DNoQx",
        "outputId": "b6acc568-a158-43e8-a54b-142b17829d8a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedReader name='automate the boring stuff with python automate the boring stuff with python ( PDFDrive ).pdf'>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VXCbh5pN-_m",
        "outputId": "f74f496b-4dde-44ee-9b46-9c332117b632"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2"
      ],
      "metadata": {
        "id": "ZgzCtLfJPUGw"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader = PyPDF2.PdfFileReader(file)"
      ],
      "metadata": {
        "id": "-6mQbmTJOkUS"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_595PGqO-9_",
        "outputId": "b72b0fec-68b8-4aad-9d30-4dfd2292c0d3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PyPDF2._reader.PdfFileReader at 0x7f3af4f28410>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(pdf_reader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcmbARdsPb9J",
        "outputId": "99c5cf1c-f833-44b6-ca17-6ad0ba166dc5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on PdfFileReader in module PyPDF2._reader object:\n",
            "\n",
            "class PdfFileReader(PdfReader)\n",
            " |  PdfFileReader(*args: Any, **kwargs: Any) -> None\n",
            " |  \n",
            " |  Initialize a PdfReader object.\n",
            " |  \n",
            " |  This operation can take some time, as the PDF stream's cross-reference\n",
            " |  tables are read into memory.\n",
            " |  \n",
            " |  :param stream: A File object or an object that supports the standard read\n",
            " |      and seek methods similar to a File object. Could also be a\n",
            " |      string representing a path to a PDF file.\n",
            " |  :param bool strict: Determines whether user should be warned of all\n",
            " |      problems and also causes some correctable problems to be fatal.\n",
            " |      Defaults to ``False``.\n",
            " |  :param None/str/bytes password: Decrypt PDF file at initialization. If the\n",
            " |      password is None, the file will not be decrypted.\n",
            " |      Defaults to ``None``\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      PdfFileReader\n",
            " |      PdfReader\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, *args: Any, **kwargs: Any) -> None\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from PdfReader:\n",
            " |  \n",
            " |  cacheGetIndirectObject(self, generation: int, idnum: int) -> Union[PyPDF2.generic.PdfObject, NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`cache_get_indirect_object` instead.\n",
            " |  \n",
            " |  cacheIndirectObject(self, generation: int, idnum: int, obj: Union[PyPDF2.generic.PdfObject, NoneType]) -> Union[PyPDF2.generic.PdfObject, NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`cache_indirect_object` instead.\n",
            " |  \n",
            " |  cache_get_indirect_object(self, generation: int, idnum: int) -> Union[PyPDF2.generic.PdfObject, NoneType]\n",
            " |  \n",
            " |  cache_indirect_object(self, generation: int, idnum: int, obj: Union[PyPDF2.generic.PdfObject, NoneType]) -> Union[PyPDF2.generic.PdfObject, NoneType]\n",
            " |  \n",
            " |  decode_permissions(self, permissions_code: int) -> Dict[str, bool]\n",
            " |  \n",
            " |  decrypt(self, password: Union[str, bytes]) -> int\n",
            " |      When using an encrypted / secured PDF file with the PDF Standard\n",
            " |      encryption handler, this function will allow the file to be decrypted.\n",
            " |      It checks the given password against the document's user password and\n",
            " |      owner password, and then stores the resulting decryption key if either\n",
            " |      password is correct.\n",
            " |      \n",
            " |      It does not matter which password was matched.  Both passwords provide\n",
            " |      the correct decryption key that will allow the document to be used with\n",
            " |      this library.\n",
            " |      \n",
            " |      :param str password: The password to match.\n",
            " |      :return: ``0`` if the password failed, ``1`` if the password matched the user\n",
            " |          password, and ``2`` if the password matched the owner password.\n",
            " |      :rtype: int\n",
            " |      :raises NotImplementedError: if document uses an unsupported encryption\n",
            " |          method.\n",
            " |  \n",
            " |  getDestinationPageNumber(self, destination: PyPDF2.generic.Destination) -> int\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`get_destination_page_number` instead.\n",
            " |  \n",
            " |  getDocumentInfo(self) -> Union[PyPDF2._reader.DocumentInformation, NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use the attribute :py:attr:`metadata` instead.\n",
            " |  \n",
            " |  getFields(self, tree: Union[PyPDF2.generic.TreeObject, NoneType] = None, retval: Union[Dict[Any, Any], NoneType] = None, fileobj: Union[Any, NoneType] = None) -> Union[Dict[str, Any], NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`get_fields` instead.\n",
            " |  \n",
            " |  getFormTextFields(self) -> Dict[str, Any]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`get_form_text_fields` instead.\n",
            " |  \n",
            " |  getIsEncrypted(self) -> bool\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`is_encrypted` instead.\n",
            " |  \n",
            " |  getNamedDestinations(self, tree: Union[PyPDF2.generic.TreeObject, NoneType] = None, retval: Union[Any, NoneType] = None) -> Dict[str, Any]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`named_destinations` instead.\n",
            " |  \n",
            " |  getNumPages(self) -> int\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :code:`len(reader.pages)` instead.\n",
            " |  \n",
            " |  getObject(self, indirectReference: PyPDF2.generic.IndirectObject) -> Union[PyPDF2.generic.PdfObject, NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`get_object` instead.\n",
            " |  \n",
            " |  getOutlines(self, node: Union[PyPDF2.generic.DictionaryObject, NoneType] = None, outlines: Union[Any, NoneType] = None) -> List[Union[PyPDF2.generic.Destination, List[Union[PyPDF2.generic.Destination, List[PyPDF2.generic.Destination]]]]]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`outlines` instead.\n",
            " |  \n",
            " |  getPage(self, pageNumber: int) -> PyPDF2._page.PageObject\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :code:`reader.pages[pageNumber]` instead.\n",
            " |  \n",
            " |  getPageLayout(self) -> Union[str, NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`page_layout` instead.\n",
            " |  \n",
            " |  getPageMode(self) -> Union[typing_extensions.Literal['/UseNone', '/UseOutlines', '/UseThumbs', '/FullScreen', '/UseOC', '/UseAttachments'], NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`page_mode` instead.\n",
            " |  \n",
            " |  getPageNumber(self, page: PyPDF2._page.PageObject) -> int\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`get_page_number` instead.\n",
            " |  \n",
            " |  getXmpMetadata(self) -> Union[PyPDF2.xmp.XmpInformation, NoneType]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use the attribute :py:attr:`xmp_metadata` instead.\n",
            " |  \n",
            " |  get_destination_page_number(self, destination: PyPDF2.generic.Destination) -> int\n",
            " |      Retrieve page number of a given Destination object.\n",
            " |      \n",
            " |      :param Destination destination: The destination to get page number.\n",
            " |      :return: the page number or -1 if page not found\n",
            " |      :rtype: int\n",
            " |  \n",
            " |  get_fields(self, tree: Union[PyPDF2.generic.TreeObject, NoneType] = None, retval: Union[Dict[Any, Any], NoneType] = None, fileobj: Union[Any, NoneType] = None) -> Union[Dict[str, Any], NoneType]\n",
            " |      Extracts field data if this PDF contains interactive form fields.\n",
            " |      The *tree* and *retval* parameters are for recursive use.\n",
            " |      \n",
            " |      :param fileobj: A file object (usually a text file) to write\n",
            " |          a report to on all interactive form fields found.\n",
            " |      :return: A dictionary where each key is a field name, and each\n",
            " |          value is a :class:`Field<PyPDF2.generic.Field>` object. By\n",
            " |          default, the mapping name is used for keys.\n",
            " |      :rtype: dict, or ``None`` if form data could not be located.\n",
            " |  \n",
            " |  get_form_text_fields(self) -> Dict[str, Any]\n",
            " |      Retrieves form fields from the document with textual data (inputs, dropdowns)\n",
            " |  \n",
            " |  get_object(self, indirect_reference: PyPDF2.generic.IndirectObject) -> Union[PyPDF2.generic.PdfObject, NoneType]\n",
            " |  \n",
            " |  get_page_number(self, page: PyPDF2._page.PageObject) -> int\n",
            " |      Retrieve page number of a given PageObject\n",
            " |      \n",
            " |      :param PageObject page: The page to get page number. Should be\n",
            " |          an instance of :class:`PageObject<PyPDF2._page.PageObject>`\n",
            " |      :return: the page number or -1 if page not found\n",
            " |      :rtype: int\n",
            " |  \n",
            " |  read(self, stream: Union[_io.BytesIO, _io.BufferedReader, _io.BufferedWriter, _io.FileIO]) -> None\n",
            " |  \n",
            " |  readNextEndLine(self, stream: Union[_io.BytesIO, _io.BufferedReader, _io.BufferedWriter, _io.FileIO], limit_offset: int = 0) -> bytes\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`read_next_end_line` instead.\n",
            " |  \n",
            " |  readObjectHeader(self, stream: Union[_io.BytesIO, _io.BufferedReader, _io.BufferedWriter, _io.FileIO]) -> Tuple[int, int]\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :meth:`read_object_header` instead.\n",
            " |  \n",
            " |  read_next_end_line(self, stream: Union[_io.BytesIO, _io.BufferedReader, _io.BufferedWriter, _io.FileIO], limit_offset: int = 0) -> bytes\n",
            " |  \n",
            " |  read_object_header(self, stream: Union[_io.BytesIO, _io.BufferedReader, _io.BufferedWriter, _io.FileIO]) -> Tuple[int, int]\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from PdfReader:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  documentInfo\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use the attribute :py:attr:`metadata` instead.\n",
            " |  \n",
            " |  isEncrypted\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`is_encrypted` instead.\n",
            " |  \n",
            " |  is_encrypted\n",
            " |      Read-only boolean property showing whether this PDF file is encrypted.\n",
            " |      Note that this property, if true, will remain true even after the\n",
            " |      :meth:`decrypt()<PyPDF2.PdfReader.decrypt>` method is called.\n",
            " |  \n",
            " |  metadata\n",
            " |      Retrieve the PDF file's document information dictionary, if it exists.\n",
            " |      Note that some PDF files use metadata streams instead of docinfo\n",
            " |      dictionaries, and these metadata streams will not be accessed by this\n",
            " |      function.\n",
            " |      \n",
            " |      :return: the document information of this PDF file\n",
            " |      :rtype: :class:`DocumentInformation<pdf.DocumentInformation>` or\n",
            " |          ``None`` if none exists.\n",
            " |  \n",
            " |  namedDestinations\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`named_destinations` instead.\n",
            " |  \n",
            " |  named_destinations\n",
            " |      A read-only dictionary which maps names to\n",
            " |      :class:`Destinations<PyPDF2.generic.Destination>`\n",
            " |  \n",
            " |  numPages\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :code:`len(reader.pages)` instead.\n",
            " |  \n",
            " |  outlines\n",
            " |      Read-only property for outlines present in the document.\n",
            " |      \n",
            " |      :return: a nested list of :class:`Destinations<PyPDF2.generic.Destination>`.\n",
            " |  \n",
            " |  pageLayout\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`page_layout` instead.\n",
            " |  \n",
            " |  pageMode\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use :py:attr:`page_mode` instead.\n",
            " |  \n",
            " |  page_layout\n",
            " |      Get the page layout.\n",
            " |      \n",
            " |      :return: Page layout currently being used.\n",
            " |      :rtype: ``str``, ``None`` if not specified\n",
            " |      \n",
            " |      .. list-table:: Valid ``layout`` values\n",
            " |         :widths: 50 200\n",
            " |      \n",
            " |         * - /NoLayout\n",
            " |           - Layout explicitly not specified\n",
            " |         * - /SinglePage\n",
            " |           - Show one page at a time\n",
            " |         * - /OneColumn\n",
            " |           - Show one column at a time\n",
            " |         * - /TwoColumnLeft\n",
            " |           - Show pages in two columns, odd-numbered pages on the left\n",
            " |         * - /TwoColumnRight\n",
            " |           - Show pages in two columns, odd-numbered pages on the right\n",
            " |         * - /TwoPageLeft\n",
            " |           - Show two pages at a time, odd-numbered pages on the left\n",
            " |         * - /TwoPageRight\n",
            " |           - Show two pages at a time, odd-numbered pages on the right\n",
            " |  \n",
            " |  page_mode\n",
            " |      Get the page mode.\n",
            " |      \n",
            " |      :return: Page mode currently being used.\n",
            " |      :rtype: ``str``, ``None`` if not specified\n",
            " |      \n",
            " |      .. list-table:: Valid ``mode`` values\n",
            " |         :widths: 50 200\n",
            " |      \n",
            " |         * - /UseNone\n",
            " |           - Do not show outlines or thumbnails panels\n",
            " |         * - /UseOutlines\n",
            " |           - Show outlines (aka bookmarks) panel\n",
            " |         * - /UseThumbs\n",
            " |           - Show page thumbnails panel\n",
            " |         * - /FullScreen\n",
            " |           - Fullscreen view\n",
            " |         * - /UseOC\n",
            " |           - Show Optional Content Group (OCG) panel\n",
            " |         * - /UseAttachments\n",
            " |           - Show attachments panel\n",
            " |  \n",
            " |  pages\n",
            " |      Read-only property that emulates a list of :py:class:`Page<PyPDF2._page.Page>` objects.\n",
            " |  \n",
            " |  xmpMetadata\n",
            " |      .. deprecated:: 1.28.0\n",
            " |      \n",
            " |          Use the attribute :py:attr:`xmp_metadata` instead.\n",
            " |  \n",
            " |  xmp_metadata\n",
            " |      XMP (Extensible Metadata Platform) data\n",
            " |      \n",
            " |      :return: a :class:`XmpInformation<xmp.XmpInformation>`\n",
            " |          instance that can be used to access XMP metadata from the document.\n",
            " |      :rtype: :class:`XmpInformation<xmp.XmpInformation>` or\n",
            " |          ``None`` if no metadata was found on the document root.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader.getIsEncrypted()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uszBDf4hPvKG",
        "outputId": "ecaaa9ca-be14-4768-b639-d3c4a27d8f8e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader.getNumPages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OLUyA3wP7gc",
        "outputId": "53c6db48-b977-4df8-a7cf-77f1f5e21c14"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "505"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page1 = pdf_reader.getPage(0)"
      ],
      "metadata": {
        "id": "Hm-yVPHbQEOi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page1.extractText())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiaq_VqwQSQQ",
        "outputId": "26f36893-c4bc-42da-be03-53f83e0b090f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRACTICAL PROGRAMMING\n",
            " \n",
            "FOR TOTAL \n",
            "BEGINNERS\n",
            "AL SWEIGART\n",
            "AUTOMATE \n",
            "THE BORING STUFF\n",
            "WITH PYTHON\n",
            "AUTOMATE \n",
            "THE BORING STUFF\n",
            "WITH PYTHON\n",
            "SHELVE IN:\n",
            "PROGRAMMING LANGUAGES/\n",
            "\n",
            "PYTHON\n",
            "$\n",
            "29\n",
            ".95 \n",
            "($\n",
            "34\n",
            ".95 CDN)\n",
            "www.nostarch.com\n",
            "THEF\n",
            "IN\n",
            "ES\n",
            "T \n",
            "I\n",
            "N \n",
            "G\n",
            "EE\n",
            "KENTE\n",
            "RT\n",
            "AINMENT\n",
            "Ž\n",
            "If you™ve ever spent hours renaming files or updating\n",
            "hundreds of spreadsheet cells, you know how tedious \n",
            "\n",
            "tasks like these can be. But what if you could have  \n",
            "\n",
            "your computer do them for you?\n",
            "minutes what would take you hours to do by hand\n",
            "Š\n",
            "learn how to use Python to write programs that do in \n",
            "In \n",
            "Automate the Boring Stuff with Python\n",
            ", you™ll\n",
            "no prior programming experience required. Once\n",
            "create Python programs that effortlessly perform \n",
            "useful and impressive feats of automation to:\n",
            "ﬁ\n",
            "I \n",
            "LIEFLAT.ﬂ\n",
            "Thi\n",
            "s \n",
            "boo\n",
            "k \n",
            "use\n",
            "sa \n",
            "dur\n",
            "ab\n",
            "l\n",
            "e \n",
            "bindin\n",
            "g \n",
            "tha\n",
            "t \n",
            "won™\n",
            "t \n",
            "sna\n",
            "p \n",
            "shu\n",
            "t.\n",
            "you™ve mastered the basics of programming, you™ll\n",
            "Search for text in a file or across multiple files\n",
            "Create, update, move, and rename files and\n",
            "folders\n",
            "Search the Web and download online content\n",
            "Update and format data in Excel spreadsheets\n",
            "of any size\n",
            "Don\n",
            "™\n",
            "t spend your time doing work a well-trained \n",
            "monkey could do. Even if you™ve never written a line \n",
            "Send reminder emails and text notifications\n",
            "Fill out online forms\n",
            "Step-by-step instructions walk you through each\n",
            "program, and practice projects at the end of each\n",
            "chapter challenge you to improve those programs and\n",
            "use your newfound skills to automate similar tasks.\n",
            "Split, merge, watermark, and encrypt PDFs\n",
            "GET STUFF DONE.\n",
            "LEARN PYTHON.\n",
            "GET STUFF DONE.\n",
            "LEARN PYTHON.\n",
            "COVERS PYTHON 3\n",
            "of code, you can make your computer do the grunt work.\n",
            "\n",
            "Learn how in \n",
            "Automate the Boring Stuff with \n",
            "Python\n",
            ".\n",
            "Python books for beginners, including \n",
            "Hacking Secret \n",
            "ABOUTTH\n",
            "E \n",
            "AUTHOR\n",
            "Al Sweigart is a software developer and teaches pro-\n",
            "gramming to kids and adults. He has written several \n",
            "Ciphers with Python\n",
            ", \n",
            "Invent YourOwn \n",
            "Computer Games \n",
            "with Python\n",
            ", and \n",
            "Making Games with Python & Pygame.\n",
            "AUTOMATE THE BORING\n",
            "STUFF WITH PYTHON\n",
            "AUTOMATE THE BORING\n",
            "STUFF WITH PYTHON\n",
            "SWEIGART\n",
            "SFI-00000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page2 = pdf_reader.getPage(1)\n"
      ],
      "metadata": {
        "id": "mRMWGK6HQT3V"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page2.extractText())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYDtAUHLQrM0",
        "outputId": "a7eed946-5220-437a-ddd0-38d0ab9a980a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUTOM\n",
            "A\n",
            "TE THE BORING STUFF \n",
            "WITH PYTHON\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page3 = pdf_reader.getPage(3)"
      ],
      "metadata": {
        "id": "NRb6LHkkQunG"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page3.extractText())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8pLDP23RNXC",
        "outputId": "a3448933-1bff-46d5-a9a6-7ba1e20eeaec"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUTOM\n",
            "A\n",
            "TE THE BORING STUFF W\n",
            "ITH PYTHON.\n",
            " Copyright © 2015 by Al Sweigart.\n",
            "All rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, \n",
            "electronic or mechanical, including photocopying, recording, or by any information storage or retrieval \n",
            "\n",
            "system, without the prior written permission of the copyright owner and the publisher.\n",
            "Printed in USA\n",
            "\n",
            "Second printing\n",
            "\n",
            "19 18 17 16 15\n",
            "  \n",
            "2 3 4 5 6 7 8 9\n",
            "ISBN-10: 1-59327-599-4\n",
            "ISBN-13: 978-1-59327-599-0\n",
            "Publisher: William Pollock\n",
            "Production Editor: Laurel Chun\n",
            "\n",
            "Cover Illustration: Josh Ellingson \n",
            "\n",
            "Interior Design: Octopod Studios\n",
            "\n",
            "Developmental Editors: Jennifer Griffith-Delgado, Greg Poulos, and Leslie Shen\n",
            "\n",
            "Technical Reviewer: Ari Lacenski\n",
            "\n",
            "Copyeditor: Kim Wimpsett\n",
            "\n",
            "Compositor: Susan Glinert Stevens\n",
            "\n",
            "Proofreader: Lisa Devoto Farrell \n",
            "\n",
            "Indexer: BIM Indexing and Proofreading Services\n",
            "For information on distribution, translations, or bulk sales,  \n",
            "please contact No Starch Press, Inc. directly:\n",
            "No Starch Press, Inc.\n",
            "245 8th Street, San Francisco, CA 94103\n",
            "\n",
            "phone: 415.863.9900; info@nostarch.com \n",
            "\n",
            "www.nostarch.com\n",
            "Library of Congress Control Number:  2014953114\n",
            "\n",
            "No Starch Press and the No Starch Press logo are registered trademarks of No Starch Press, Inc. Other \n",
            "product and company names mentioned herein may be the trademarks of their respective owners. Rather \n",
            "\n",
            "than use a trademark symbol with every occurrence of a trademarked name, we are using the names only \n",
            "in an editorial fashion and to the benefit of the trademark owner, with no intention of infringement of the \n",
            "\n",
            "trademark.\n",
            "The information in this book is distributed on an ﬁAs Isﬂ basis, without warranty. While every precaution \n",
            "has been taken in the preparation of this work, neither the author nor No Starch Press, Inc. shall have any \n",
            "\n",
            "liability to any person or entity with respect to any loss or damage caused or alleged to be caused directly or \n",
            "\n",
            "indirectly by the information contained in it.\n",
            "This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United \n",
            "States License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-sa/3.0/us/ \n",
            "\n",
            "or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
            "SFI-00000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ],
      "metadata": {
        "id": "2JS9Xsb4RPSr"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = list(STOP_WORDS)"
      ],
      "metadata": {
        "id": "Q-ia7gFs9Jel"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "qXLV8ut49SxQ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = ''' Commercial products\n",
        "In 2022 Google Docs released an automatic summarization feature.[6]\n",
        "\n",
        "Approaches\n",
        "There are two general approaches to automatic summarization: extraction and abstraction.\n",
        "\n",
        "Extraction-based summarization\n",
        "Here, content is extracted from the original data, but the extracted content is not modified in any way. Examples of extracted content include key-phrases that can be used to \"tag\" or index a text document, or key sentences (including headings) that collectively comprise an abstract, and representative images or video segments, as stated above. For text, extraction is analogous to the process of skimming, where the summary (if available), headings and subheadings, figures, the first and last paragraphs of a section, and optionally the first and last sentences in a paragraph are read before one chooses to read the entire document in detail.[7] Other examples of extraction that include key sequences of text in terms of clinical relevance (including patient/problem, intervention, and outcome).[8]\n",
        "\n",
        "Abstraction-based summarization\n",
        "This has been applied mainly for text. Abstractive methods build an internal semantic representation of the original content, and then use this representation to create a summary that is closer to what a human might express. Abstraction may transform the extracted content by paraphrasing sections of the source document, to condense a text more strongly than extraction. Such transformation, however, is computationally much more challenging than extraction, involving both natural language processing and often a deep understanding of the domain of the original text in cases where the original document relates to a special field of knowledge. \"Paraphrasing\" is even more difficult to apply to image and video, which is why most summarization systems are extractive.\n",
        "\n",
        "Aided summarization\n",
        "Approaches aimed at higher summarization quality rely on combined software and human effort. In Machine Aided Human Summarization, extractive techniques highlight candidate passages for inclusion (to which the human adds or removes text). In Human Aided Machine Summarization, a human post-processes software output, in the same way that one edits the output of automatic translation by Google Translate.\n",
        "\n",
        "Applications and systems for summarization\n",
        "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
        "\n",
        "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
        "\n",
        "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[9] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
        "\n",
        "At a very high level, summarization algorithms try to find subsets of objects (like set of sentences, or a set of images), which cover information of the entire set. This is also called the core-set. These algorithms model notions like diversity, coverage, information and representativeness of the summary. Query based summarization techniques, additionally model for relevance of the summary with the query. Some techniques and algorithms which naturally model summarization problems are TextRank and PageRank, Submodular set function, Determinantal point process, maximal marginal relevance (MMR) etc.\n",
        "\n",
        "Keyphrase extraction\n",
        "The task is the following. You are given a piece of text, such as a journal article, and you must produce a list of keywords or key[phrase]s that capture the primary topics discussed in the text.[10] In the case of research articles, many authors provide manually assigned keywords, but most text lacks pre-existing keyphrases. For example, news articles rarely have keyphrases attached, but it would be useful to be able to automatically do so for a number of applications discussed below. Consider the example text from a news article:\n",
        "\n",
        "\"The Army Corps of Engineers, rushing to meet President Bush's promise to protect New Orleans by the start of the 2006 hurricane season, installed defective flood-control pumps last year despite warnings from its own expert that the equipment would fail during a storm, according to documents obtained by The Associated Press\".\n",
        "A keyphrase extractor might select \"Army Corps of Engineers\", \"President Bush\", \"New Orleans\", and \"defective flood-control pumps\" as keyphrases. These are pulled directly from the text. In contrast, an abstractive keyphrase system would somehow internalize the content and generate keyphrases that do not appear in the text, but more closely resemble what a human might produce, such as \"political negligence\" or \"inadequate protection from floods\". Abstraction requires a deep understanding of the text, which makes it difficult for a computer system. Keyphrases have many applications. They can enable document browsing by providing a short summary, improve information retrieval (if documents have keyphrases assigned, a user could search by keyphrase to produce more reliable hits than a full-text search), and be employed in generating index entries for a large text corpus.\n",
        "\n",
        "Depending on the different literature and the definition of key terms, words or phrases, keyword extraction is a highly related theme.\n",
        "\n",
        "Supervised learning approaches\n",
        "Beginning with the work of Turney,[11] many researchers have approached keyphrase extraction as a supervised machine learning problem. Given a document, we construct an example for each unigram, bigram, and trigram found in the text (though other text units are also possible, as discussed below). We then compute various features describing each example (e.g., does the phrase begin with an upper-case letter?). We assume there are known keyphrases available for a set of training documents. Using the known keyphrases, we can assign positive or negative labels to the examples. Then we learn a classifier that can discriminate between positive and negative examples as a function of the features. Some classifiers make a binary classification for a test example, while others assign a probability of being a keyphrase. For instance, in the above text, we might learn a rule that says phrases with initial capital letters are likely to be keyphrases. After training a learner, we can select keyphrases for test documents in the following manner. We apply the same example-generation strategy to the test documents, then run each example through the learner. We can determine the keyphrases by looking at binary classification decisions or probabilities returned from our learned model. If probabilities are given, a threshold is used to select the keyphrases. Keyphrase extractors are generally evaluated using precision and recall. Precision measures how many of the proposed keyphrases are actually correct. Recall measures how many of the true keyphrases your system proposed. The two measures can be combined in an F-score, which is the harmonic mean of the two (F = 2PR/(P + R) ). Matches between the proposed keyphrases and the known keyphrases can be checked after stemming or applying some other text normalization.\n",
        "\n",
        "Designing a supervised keyphrase extraction system involves deciding on several choices (some of these apply to unsupervised, too). The first choice is exactly how to generate examples. Turney and others have used all possible unigrams, bigrams, and trigrams without intervening punctuation and after removing stopwords. Hulth showed that you can get some improvement by selecting examples to be sequences of tokens that match certain patterns of part-of-speech tags. Ideally, the mechanism for generating examples produces all the known labeled keyphrases as candidates, though this is often not the case. For example, if we use only unigrams, bigrams, and trigrams, then we will never be able to extract a known keyphrase containing four words. Thus, recall may suffer. However, generating too many examples can also lead to low precision.\n",
        "\n",
        "We also need to create features that describe the examples and are informative enough to allow a learning algorithm to discriminate keyphrases from non- keyphrases. Typically features involve various term frequencies (how many times a phrase appears in the current text or in a larger corpus), the length of the example, relative position of the first occurrence, various boolean syntactic features (e.g., contains all caps), etc. The Turney paper used about 12 such features. Hulth uses a reduced set of features, which were found most successful in the KEA (Keyphrase Extraction Algorithm) work derived from Turney's seminal paper.\n",
        "\n",
        "In the end, the system will need to return a list of keyphrases for a test document, so we need to have a way to limit the number. Ensemble methods (i.e., using votes from several classifiers) have been used to produce numeric scores that can be thresholded to provide a user-provided number of keyphrases. This is the technique used by Turney with C4.5 decision trees. Hulth used a single binary classifier so the learning algorithm implicitly determines the appropriate number.\n",
        "\n",
        "Once examples and features are created, we need a way to learn to predict keyphrases. Virtually any supervised learning algorithm could be used, such as decision trees, Naive Bayes, and rule induction. In the case of Turney's GenEx algorithm, a genetic algorithm is used to learn parameters for a domain-specific keyphrase extraction algorithm. The extractor follows a series of heuristics to identify keyphrases. The genetic algorithm optimizes parameters for these heuristics with respect to performance on training documents with known key phrases.\n",
        "\n",
        "Unsupervised approach: TextRank\n",
        "Another keyphrase extraction algorithm is TextRank. While supervised methods have some nice properties, like being able to produce interpretable rules for what features characterize a keyphrase, they also require a large amount of training data. Many documents with known keyphrases are needed. Furthermore, training on a specific domain tends to customize the extraction process to that domain, so the resulting classifier is not necessarily portable, as some of Turney's results demonstrate. Unsupervised keyphrase extraction removes the need for training data. It approaches the problem from a different angle. Instead of trying to learn explicit features that characterize keyphrases, the TextRank algorithm[12] exploits the structure of the text itself to determine keyphrases that appear \"central\" to the text in the same way that PageRank selects important Web pages. Recall this is based on the notion of \"prestige\" or \"recommendation\" from social networks. In this way, TextRank does not rely on any previous training data at all, but rather can be run on any arbitrary piece of text, and it can produce output simply based on the text's intrinsic properties. Thus the algorithm is easily portable to new domains and languages.\n",
        "\n",
        "TextRank is a general purpose graph-based ranking algorithm for NLP. Essentially, it runs PageRank on a graph specially designed for a particular NLP task. For keyphrase extraction, it builds a graph using some set of text units as vertices. Edges are based on some measure of semantic or lexical similarity between the text unit vertices. Unlike PageRank, the edges are typically undirected and can be weighted to reflect a degree of similarity. Once the graph is constructed, it is used to form a stochastic matrix, combined with a damping factor (as in the \"random surfer model\"), and the ranking over vertices is obtained by finding the eigenvector corresponding to eigenvalue 1 (i.e., the stationary distribution of the random walk on the graph).\n",
        "\n",
        "The vertices should correspond to what we want to rank. Potentially, we could do something similar to the supervised methods and create a vertex for each unigram, bigram, trigram, etc. However, to keep the graph small, the authors decide to rank individual unigrams in a first step, and then include a second step that merges highly ranked adjacent unigrams to form multi-word phrases. This has a nice side effect of allowing us to produce keyphrases of arbitrary length. For example, if we rank unigrams and find that \"advanced\", \"natural\", \"language\", and \"processing\" all get high ranks, then we would look at the original text and see that these words appear consecutively and create a final keyphrase using all four together. Note that the unigrams placed in the graph can be filtered by part of speech. The authors found that adjectives and nouns were the best to include. Thus, some linguistic knowledge comes into play in this step.\n",
        "\n",
        "Edges are created based on word co-occurrence in this application of TextRank. Two vertices are connected by an edge if the unigrams appear within a window of size N in the original text. N is typically around 2–10. Thus, \"natural\" and \"language\" might be linked in a text about NLP. \"Natural\" and \"processing\" would also be linked because they would both appear in the same string of N words. These edges build on the notion of \"text cohesion\" and the idea that words that appear near each other are likely related in a meaningful way and \"recommend\" each other to the reader.\n",
        "\n",
        "Since this method simply ranks the individual vertices, we need a way to threshold or produce a limited number of keyphrases. The technique chosen is to set a count T to be a user-specified fraction of the total number of vertices in the graph. Then the top T vertices/unigrams are selected based on their stationary probabilities. A post- processing step is then applied to merge adjacent instances of these T unigrams. As a result, potentially more or less than T final keyphrases will be produced, but the number should be roughly proportional to the length of the original text.\n",
        "\n",
        "It is not initially clear why applying PageRank to a co-occurrence graph would produce useful keyphrases. One way to think about it is the following. A word that appears multiple times throughout a text may have many different co-occurring neighbors. For example, in a text about machine learning, the unigram \"learning\" might co-occur with \"machine\", \"supervised\", \"un-supervised\", and \"semi-supervised\" in four different sentences. Thus, the \"learning\" vertex would be a central \"hub\" that connects to these other modifying words. Running PageRank/TextRank on the graph is likely to rank \"learning\" highly. Similarly, if the text contains the phrase \"supervised classification\", then there would be an edge between \"supervised\" and \"classification\". If \"classification\" appears several other places and thus has many neighbors, its importance would contribute to the importance of \"supervised\". If it ends up with a high rank, it will be selected as one of the top T unigrams, along with \"learning\" and probably \"classification\". In the final post-processing step, we would then end up with keyphrases \"supervised learning\" and \"supervised classification\".\n",
        "\n",
        "In short, the co-occurrence graph will contain densely connected regions for terms that appear often and in different contexts. A random walk on this graph will have a stationary distribution that assigns large probabilities to the terms in the centers of the clusters. This is similar to densely connected Web pages getting ranked highly by PageRank. This approach has also been used in document summarization, considered below.\n",
        "\n",
        "Document summarization\n",
        "Like keyphrase extraction, document summarization aims to identify the essence of a text. The only real difference is that now we are dealing with larger text units—whole sentences instead of words and phrases.\n",
        "\n",
        "Before getting into the details of some summarization methods, we will mention how summarization systems are typically evaluated. The most common way is using the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure. This is a recall-based measure that determines how well a system-generated summary covers the content present in one or more human-generated model summaries known as references. It is recall-based to encourage systems to include all the important topics in the text. Recall can be computed with respect to unigram, bigram, trigram, or 4-gram matching. For example, ROUGE-1 is computed as division of count of unigrams in reference that appear in system and count of unigrams in reference summary.\n",
        "\n",
        "If there are multiple references, the ROUGE-1 scores are averaged. Because ROUGE is based only on content overlap, it can determine if the same general concepts are discussed between an automatic summary and a reference summary, but it cannot determine if the result is coherent or the sentences flow together in a sensible manner. High-order n-gram ROUGE measures try to judge fluency to some degree. Note that ROUGE is similar to the BLEU measure for machine translation, but BLEU is precision- based, because translation systems favor accuracy.\n",
        "\n",
        "A promising line in document summarization is adaptive document/text summarization.[13] The idea of adaptive summarization involves preliminary recognition of document/text genre and subsequent application of summarization algorithms optimized for this genre. First summarizes that perform adaptive summarization have been created.[14]\n",
        "\n",
        "Supervised learning approaches\n",
        "Supervised text summarization is very much like supervised keyphrase extraction. Basically, if you have a collection of documents and human-generated summaries for them, you can learn features of sentences that make them good candidates for inclusion in the summary. Features might include the position in the document (i.e., the first few sentences are probably important), the number of words in the sentence, etc. The main difficulty in supervised extractive summarization is that the known summaries must be manually created by extracting sentences so the sentences in an original training document can be labeled as \"in summary\" or \"not in summary\". This is not typically how people create summaries, so simply using journal abstracts or existing summaries is usually not sufficient. The sentences in these summaries do not necessarily match up with sentences in the original text, so it would be difficult to assign labels to examples for training. Note, however, that these natural summaries can still be used for evaluation purposes, since ROUGE-1 only cares about unigrams.\n",
        "\n",
        "Maximum entropy-based summarization\n",
        "During the DUC 2001 and 2002 evaluation workshops, TNO developed a sentence extraction system for multi-document summarization in the news domain. The system was based on a hybrid system using a naive Bayes classifier and statistical language models for modeling salience. Although the system exhibited good results, the researchers wanted to explore the effectiveness of a maximum entropy (ME) classifier for the meeting summarization task, as ME is known to be robust against feature dependencies. Maximum entropy has also been applied successfully for summarization in the broadcast news domain.\n",
        "\n",
        "TextRank and LexRank\n",
        "The unsupervised approach to summarization is also quite similar in spirit to unsupervised keyphrase extraction and gets around the issue of costly training data. Some unsupervised summarization approaches are based on finding a \"centroid\" sentence, which is the mean word vector of all the sentences in the document. Then the sentences can be ranked with regard to their similarity to this centroid sentence.\n",
        "\n",
        "A more principled way to estimate sentence importance is using random walks and eigenvector centrality. LexRank[15] is an algorithm essentially identical to TextRank, and both use this approach for document summarization. The two methods were developed by different groups at the same time, and LexRank simply focused on summarization, but could just as easily be used for keyphrase extraction or any other NLP ranking task.\n",
        "\n",
        "In both LexRank and TextRank, a graph is constructed by creating a vertex for each sentence in the document.\n",
        "\n",
        "The edges between sentences are based on some form of semantic similarity or content overlap. While LexRank uses cosine similarity of TF-IDF vectors, TextRank uses a very similar measure based on the number of words two sentences have in common (normalized by the sentences' lengths). The LexRank paper explored using unweighted edges after applying a threshold to the cosine values, but also experimented with using edges with weights equal to the similarity score. TextRank uses continuous similarity scores as weights.\n",
        "\n",
        "In both algorithms, the sentences are ranked by applying PageRank to the resulting graph. A summary is formed by combining the top ranking sentences, using a threshold or length cutoff to limit the size of the summary.\n",
        "\n",
        "It is worth noting that TextRank was applied to summarization exactly as described here, while LexRank was used as part of a larger summarization system (MEAD) that combines the LexRank score (stationary probability) with other features like sentence position and length using a linear combination with either user-specified or automatically tuned weights. In this case, some training documents might be needed, though the TextRank results show the additional features are not absolutely necessary.\n",
        "\n",
        "Another important distinction is that TextRank was used for single document summarization, while LexRank has been applied to multi-document summarization. The task remains the same in both cases—only the number of sentences to choose from has grown. However, when summarizing multiple documents, there is a greater risk of selecting duplicate or highly redundant sentences to place in the same summary. Imagine you have a cluster of news articles on a particular event, and you want to produce one summary. Each article is likely to have many similar sentences, and you would only want to include distinct ideas in the summary. To address this issue, LexRank applies a heuristic post-processing step that builds up a summary by adding sentences in rank order, but discards any sentences that are too similar to ones already placed in the summary. The method used is called Cross-Sentence Information Subsumption (CSIS).\n",
        "\n",
        "These methods work based on the idea that sentences \"recommend\" other similar sentences to the reader. Thus, if one sentence is very similar to many others, it will likely be a sentence of great importance. The importance of this sentence also stems from the importance of the sentences \"recommending\" it. Thus, to get ranked highly and placed in a summary, a sentence must be similar to many sentences that are in turn also similar to many other sentences. This makes intuitive sense and allows the algorithms to be applied to any arbitrary new text. The methods are domain-independent and easily portable. One could imagine the features indicating important sentences in the news domain might vary considerably from the biomedical domain. However, the unsupervised \"recommendation\"-based approach applies to any domain.\n",
        "\n",
        "Multi-document summarization\n",
        "Main article: Multi-document summarization\n",
        "Multi-document summarization is an automatic procedure aimed at extraction of information from multiple texts written about the same topic. Resulting summary report allows individual users, such as professional information consumers, to quickly familiarize themselves with information contained in a large cluster of documents. In such a way, multi-document summarization systems are complementing the news aggregators performing the next step down the road of coping with information overload. Multi-document summarization may also be done in response to a question.[16][8]\n",
        "\n",
        "Multi-document summarization creates information reports that are both concise and comprehensive. With different opinions being put together and outlined, every topic is described from multiple perspectives within a single document. While the goal of a brief summary is to simplify information search and cut the time by pointing to the most relevant source documents, comprehensive multi-document summary should itself contain the required information, hence limiting the need for accessing original files to cases when refinement is required. Automatic summaries present information extracted from multiple sources algorithmically, without any editorial touch or subjective human intervention, thus making it completely unbiased.[dubious – discuss]\n",
        "\n",
        "Incorporating diversity\n",
        "Multi-document extractive summarization faces a problem of potential redundancy. Ideally, we would like to extract sentences that are both \"central\" (i.e., contain the main ideas) and \"diverse\" (i.e., they differ from one another). LexRank deals with diversity as a heuristic final stage using CSIS, and other systems have used similar methods, such as Maximal Marginal Relevance (MMR),[17] in trying to eliminate redundancy in information retrieval results. There is a general purpose graph-based ranking algorithm like Page/Lex/TextRank that handles both \"centrality\" and \"diversity\" in a unified mathematical framework based on absorbing Markov chain random walks. (An absorbing random walk is like a standard random walk, except some states are now absorbing states that act as \"black holes\" that cause the walk to end abruptly at that state.) The algorithm is called GRASSHOPPER.[18] In addition to explicitly promoting diversity during the ranking process, GRASSHOPPER incorporates a prior ranking (based on sentence position in the case of summarization).\n",
        "\n",
        "The state of the art results for multi-document summarization, however, are obtained using mixtures of submodular functions. These methods have achieved the state of the art results for Document Summarization Corpora, DUC 04 - 07.[19] Similar results were also achieved with the use of determinantal point processes (which are a special case of submodular functions) for DUC-04.[20]\n",
        "\n",
        "A new method for multi-lingual multi-document summarization that avoids redundancy works by simplifying and generating ideograms that represent the meaning of each sentence in each document and then evaluates similarity \"qualitatively\" by comparing the shape and position of said ideograms has recently been developed. This tool does not use word frequency, does not need training or preprocessing of any kind and works by generating ideograms that represent the meaning of each sentence and then summarizes using two user-supplied parameters: equivalence (when are two sentences to be considered equivalent) and relevance (how long is the desired summary).\n",
        "\n",
        "Submodular functions as generic tools for summarization\n",
        "The idea of a submodular set function has recently emerged as a powerful modeling tool for various summarization problems. Submodular functions naturally model notions of coverage, information, representation and diversity. Moreover, several important combinatorial optimization problems occur as special instances of submodular optimization. For example, the set cover problem is a special case of submodular optimization, since the set cover function is submodular. The set cover function attempts to find a subset of objects which cover a given set of concepts. For example, in document summarization, one would like the summary to cover all important and relevant concepts in the document. This is an instance of set cover. Similarly, the facility location problem is a special case of submodular functions. The Facility Location function also naturally models coverage and diversity. Another example of a submodular optimization problem is using a determinantal point process to model diversity. Similarly, the Maximum-Marginal-Relevance procedure can also be seen as an instance of submodular optimization. All these important models encouraging coverage, diversity and information are all submodular. Moreover, submodular functions can be efficiently combined, and the resulting function is still submodular. Hence, one could combine one submodular function which models diversity, another one which models coverage and use human supervision to learn a right model of a submodular function for the problem.\n",
        "\n",
        "While submodular functions are fitting problems for summarization, they also admit very efficient algorithms for optimization. For example, a simple greedy algorithm admits a constant factor guarantee.[21] Moreover, the greedy algorithm is extremely simple to implement and can scale to large datasets, which is very important for summarization problems.\n",
        "\n",
        "Submodular functions have achieved state-of-the-art for almost all summarization problems. For example, work by Lin and Bilmes, 2012[22] shows that submodular functions achieve the best results to date on DUC-04, DUC-05, DUC-06 and DUC-07 systems for document summarization. Similarly, work by Lin and Bilmes, 2011,[23] shows that many existing systems for automatic summarization are instances of submodular functions. This was a breakthrough result establishing submodular functions as the right models for summarization problems.[citation needed]\n",
        "\n",
        "Submodular Functions have also been used for other summarization tasks. Tschiatschek et al., 2014 show[24] that mixtures of submodular functions achieve state-of-the-art results for image collection summarization. Similarly, Bairi et al., 2015[25] show the utility of submodular functions for summarizing multi-document topic hierarchies. Submodular Functions have also successfully been used for summarizing machine learning datasets.[26]\n",
        "\n",
        "Applications\n",
        "[icon]\t\n",
        "This section needs expansion. You can help by adding to it. (February 2017)\n",
        "Specific applications of automatic summarization include:\n",
        "\n",
        "The Reddit bot \"autotldr\",[27] created in 2011 summarizes news articles in the comment-section of reddit posts. It was found to be very useful by the reddit community which upvoted its summaries hundreds of thousands of times.[28] The name is reference to TL;DR − Internet slang for \"too long; didn't read\".[29][30]\n",
        "Evaluation techniques\n",
        "The most common way to evaluate the informativeness of automatic summaries is to compare them with human-made model summaries.\n",
        "\n",
        "Evaluation techniques fall into intrinsic and extrinsic,[31] inter-textual and intra-textual.[32]\n",
        "\n",
        "Intrinsic and extrinsic evaluation\n",
        "An intrinsic evaluation tests the summarization system in and of itself while an extrinsic evaluation tests the summarization based on how it affects the completion of some other task. Intrinsic evaluations have assessed mainly the coherence and informativeness of summaries. Extrinsic evaluations, on the other hand, have tested the impact of summarization on tasks like relevance assessment, reading comprehension, etc.\n",
        "\n",
        "Inter-textual and intra-textual\n",
        "Intra-textual methods assess the output of a specific summarization system, and the inter-textual ones focus on contrastive analysis of outputs of several summarization systems.\n",
        "\n",
        "Human judgement often has wide variance on what is considered a \"good\" summary, which means that making the evaluation process automatic is particularly difficult. Manual evaluation can be used, but this is both time and labor-intensive as it requires humans to read not only the summaries but also the source documents. Other issues are those concerning coherence and coverage.\n",
        "\n",
        "One of the metrics used in NIST's annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation [2]). It essentially calculates n-gram overlaps between automatically generated summaries and previously written human summaries. A high level of overlap should indicate a high level of shared concepts between the two summaries. Note that overlap metrics like this are unable to provide any feedback on a summary's coherence. Anaphor resolution remains another problem yet to be fully solved. Similarly, for image summarization, Tschiatschek et al., developed a Visual-ROUGE score which judges the performance of algorithms for image summarization.[33]\n",
        "\n",
        "Domain specific versus domain independent summarization techniques\n",
        "Domain independent summarization techniques generally apply sets of general features which can be used to identify information-rich text segments. Recent research focus has drifted to domain-specific summarization techniques that utilize the available knowledge specific to the domain of text. For example, automatic summarization research on medical text generally attempts to utilize the various sources of codified medical knowledge and ontologies.[34]\n",
        "\n",
        "Evaluating summaries qualitatively\n",
        "The main drawback of the evaluation systems existing so far is that we need at least one reference summary, and for some methods more than one, to be able to compare automatic summaries with models. This is a hard and expensive task. Much effort has to be done in order to have corpus of texts and their corresponding summaries. Furthermore, for some methods, not only do we need to have human-made summaries available for comparison, but also manual annotation has to be performed in some of them (e.g. SCU in the Pyramid Method). In any case, what the evaluation methods need as an input, is a set of summaries to serve as gold standards and a set of automatic summaries. Moreover, they all perform a quantitative evaluation with regard to different similarity metrics.\n",
        "\n",
        "History\n",
        "The first publication in the area dates back to 1957 [35] (Hans Peter Luhn), starting with a statistical technique. Research increased significantly in 2015. Term frequency–inverse document frequency had been used by 2016. Pattern-based summarization was the most powerful option for multi-document summarization found by 2016. In the following year it was surpassed by latent semantic analysis (LSA) combined with non-negative matrix factorization (NMF). Although they did not replace other approaches and are often combined with them, by 2019 machine learning methods dominated the extractive summarization of single documents, which was considered to be nearing maturity. By 2020, the field was still very active and research is shifting towards abstractive summation and real-time summarization.[36]\n",
        "\n",
        "Recent approaches\n",
        "Recently the rise of Transformer models replacing more traditional RNN (LSTM) have provided a flexibility in the mapping of text sequences to text sequences of a different type, which is well suited to automatic summarization. This includes models such as T5[37] and Pegasus. '''"
      ],
      "metadata": {
        "id": "GwhtCELV9bZ-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(txt)"
      ],
      "metadata": {
        "id": "Na53M74r9r2z"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TOKENIZING THE TEXT**"
      ],
      "metadata": {
        "id": "uSkWIlP_-zUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]\n",
        "print(tokens) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xKOQ2Vc-A5d",
        "outputId": "fac8a0e3-a046-4fd9-8efa-241597bd4fc4"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', 'Commercial', 'products', '\\n', 'In', '2022', 'Google', 'Docs', 'released', 'an', 'automatic', 'summarization', 'feature.[6', ']', '\\n\\n', 'Approaches', '\\n', 'There', 'are', 'two', 'general', 'approaches', 'to', 'automatic', 'summarization', ':', 'extraction', 'and', 'abstraction', '.', '\\n\\n', 'Extraction', '-', 'based', 'summarization', '\\n', 'Here', ',', 'content', 'is', 'extracted', 'from', 'the', 'original', 'data', ',', 'but', 'the', 'extracted', 'content', 'is', 'not', 'modified', 'in', 'any', 'way', '.', 'Examples', 'of', 'extracted', 'content', 'include', 'key', '-', 'phrases', 'that', 'can', 'be', 'used', 'to', '\"', 'tag', '\"', 'or', 'index', 'a', 'text', 'document', ',', 'or', 'key', 'sentences', '(', 'including', 'headings', ')', 'that', 'collectively', 'comprise', 'an', 'abstract', ',', 'and', 'representative', 'images', 'or', 'video', 'segments', ',', 'as', 'stated', 'above', '.', 'For', 'text', ',', 'extraction', 'is', 'analogous', 'to', 'the', 'process', 'of', 'skimming', ',', 'where', 'the', 'summary', '(', 'if', 'available', ')', ',', 'headings', 'and', 'subheadings', ',', 'figures', ',', 'the', 'first', 'and', 'last', 'paragraphs', 'of', 'a', 'section', ',', 'and', 'optionally', 'the', 'first', 'and', 'last', 'sentences', 'in', 'a', 'paragraph', 'are', 'read', 'before', 'one', 'chooses', 'to', 'read', 'the', 'entire', 'document', 'in', 'detail.[7', ']', 'Other', 'examples', 'of', 'extraction', 'that', 'include', 'key', 'sequences', 'of', 'text', 'in', 'terms', 'of', 'clinical', 'relevance', '(', 'including', 'patient', '/', 'problem', ',', 'intervention', ',', 'and', 'outcome).[8', ']', '\\n\\n', 'Abstraction', '-', 'based', 'summarization', '\\n', 'This', 'has', 'been', 'applied', 'mainly', 'for', 'text', '.', 'Abstractive', 'methods', 'build', 'an', 'internal', 'semantic', 'representation', 'of', 'the', 'original', 'content', ',', 'and', 'then', 'use', 'this', 'representation', 'to', 'create', 'a', 'summary', 'that', 'is', 'closer', 'to', 'what', 'a', 'human', 'might', 'express', '.', 'Abstraction', 'may', 'transform', 'the', 'extracted', 'content', 'by', 'paraphrasing', 'sections', 'of', 'the', 'source', 'document', ',', 'to', 'condense', 'a', 'text', 'more', 'strongly', 'than', 'extraction', '.', 'Such', 'transformation', ',', 'however', ',', 'is', 'computationally', 'much', 'more', 'challenging', 'than', 'extraction', ',', 'involving', 'both', 'natural', 'language', 'processing', 'and', 'often', 'a', 'deep', 'understanding', 'of', 'the', 'domain', 'of', 'the', 'original', 'text', 'in', 'cases', 'where', 'the', 'original', 'document', 'relates', 'to', 'a', 'special', 'field', 'of', 'knowledge', '.', '\"', 'Paraphrasing', '\"', 'is', 'even', 'more', 'difficult', 'to', 'apply', 'to', 'image', 'and', 'video', ',', 'which', 'is', 'why', 'most', 'summarization', 'systems', 'are', 'extractive', '.', '\\n\\n', 'Aided', 'summarization', '\\n', 'Approaches', 'aimed', 'at', 'higher', 'summarization', 'quality', 'rely', 'on', 'combined', 'software', 'and', 'human', 'effort', '.', 'In', 'Machine', 'Aided', 'Human', 'Summarization', ',', 'extractive', 'techniques', 'highlight', 'candidate', 'passages', 'for', 'inclusion', '(', 'to', 'which', 'the', 'human', 'adds', 'or', 'removes', 'text', ')', '.', 'In', 'Human', 'Aided', 'Machine', 'Summarization', ',', 'a', 'human', 'post', '-', 'processes', 'software', 'output', ',', 'in', 'the', 'same', 'way', 'that', 'one', 'edits', 'the', 'output', 'of', 'automatic', 'translation', 'by', 'Google', 'Translate', '.', '\\n\\n', 'Applications', 'and', 'systems', 'for', 'summarization', '\\n', 'There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', 'what', 'the', 'user', 'needs', '.', '\\n\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', 'as', 'a', 'summary', '.', '\\n\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[9', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured', '.', '\\n\\n', 'At', 'a', 'very', 'high', 'level', ',', 'summarization', 'algorithms', 'try', 'to', 'find', 'subsets', 'of', 'objects', '(', 'like', 'set', 'of', 'sentences', ',', 'or', 'a', 'set', 'of', 'images', ')', ',', 'which', 'cover', 'information', 'of', 'the', 'entire', 'set', '.', 'This', 'is', 'also', 'called', 'the', 'core', '-', 'set', '.', 'These', 'algorithms', 'model', 'notions', 'like', 'diversity', ',', 'coverage', ',', 'information', 'and', 'representativeness', 'of', 'the', 'summary', '.', 'Query', 'based', 'summarization', 'techniques', ',', 'additionally', 'model', 'for', 'relevance', 'of', 'the', 'summary', 'with', 'the', 'query', '.', 'Some', 'techniques', 'and', 'algorithms', 'which', 'naturally', 'model', 'summarization', 'problems', 'are', 'TextRank', 'and', 'PageRank', ',', 'Submodular', 'set', 'function', ',', 'Determinantal', 'point', 'process', ',', 'maximal', 'marginal', 'relevance', '(', 'MMR', ')', 'etc', '.', '\\n\\n', 'Keyphrase', 'extraction', '\\n', 'The', 'task', 'is', 'the', 'following', '.', 'You', 'are', 'given', 'a', 'piece', 'of', 'text', ',', 'such', 'as', 'a', 'journal', 'article', ',', 'and', 'you', 'must', 'produce', 'a', 'list', 'of', 'keywords', 'or', 'key[phrase]s', 'that', 'capture', 'the', 'primary', 'topics', 'discussed', 'in', 'the', 'text.[10', ']', 'In', 'the', 'case', 'of', 'research', 'articles', ',', 'many', 'authors', 'provide', 'manually', 'assigned', 'keywords', ',', 'but', 'most', 'text', 'lacks', 'pre', '-', 'existing', 'keyphrases', '.', 'For', 'example', ',', 'news', 'articles', 'rarely', 'have', 'keyphrases', 'attached', ',', 'but', 'it', 'would', 'be', 'useful', 'to', 'be', 'able', 'to', 'automatically', 'do', 'so', 'for', 'a', 'number', 'of', 'applications', 'discussed', 'below', '.', 'Consider', 'the', 'example', 'text', 'from', 'a', 'news', 'article', ':', '\\n\\n', '\"', 'The', 'Army', 'Corps', 'of', 'Engineers', ',', 'rushing', 'to', 'meet', 'President', 'Bush', \"'s\", 'promise', 'to', 'protect', 'New', 'Orleans', 'by', 'the', 'start', 'of', 'the', '2006', 'hurricane', 'season', ',', 'installed', 'defective', 'flood', '-', 'control', 'pumps', 'last', 'year', 'despite', 'warnings', 'from', 'its', 'own', 'expert', 'that', 'the', 'equipment', 'would', 'fail', 'during', 'a', 'storm', ',', 'according', 'to', 'documents', 'obtained', 'by', 'The', 'Associated', 'Press', '\"', '.', '\\n', 'A', 'keyphrase', 'extractor', 'might', 'select', '\"', 'Army', 'Corps', 'of', 'Engineers', '\"', ',', '\"', 'President', 'Bush', '\"', ',', '\"', 'New', 'Orleans', '\"', ',', 'and', '\"', 'defective', 'flood', '-', 'control', 'pumps', '\"', 'as', 'keyphrases', '.', 'These', 'are', 'pulled', 'directly', 'from', 'the', 'text', '.', 'In', 'contrast', ',', 'an', 'abstractive', 'keyphrase', 'system', 'would', 'somehow', 'internalize', 'the', 'content', 'and', 'generate', 'keyphrases', 'that', 'do', 'not', 'appear', 'in', 'the', 'text', ',', 'but', 'more', 'closely', 'resemble', 'what', 'a', 'human', 'might', 'produce', ',', 'such', 'as', '\"', 'political', 'negligence', '\"', 'or', '\"', 'inadequate', 'protection', 'from', 'floods', '\"', '.', 'Abstraction', 'requires', 'a', 'deep', 'understanding', 'of', 'the', 'text', ',', 'which', 'makes', 'it', 'difficult', 'for', 'a', 'computer', 'system', '.', 'Keyphrases', 'have', 'many', 'applications', '.', 'They', 'can', 'enable', 'document', 'browsing', 'by', 'providing', 'a', 'short', 'summary', ',', 'improve', 'information', 'retrieval', '(', 'if', 'documents', 'have', 'keyphrases', 'assigned', ',', 'a', 'user', 'could', 'search', 'by', 'keyphrase', 'to', 'produce', 'more', 'reliable', 'hits', 'than', 'a', 'full', '-', 'text', 'search', ')', ',', 'and', 'be', 'employed', 'in', 'generating', 'index', 'entries', 'for', 'a', 'large', 'text', 'corpus', '.', '\\n\\n', 'Depending', 'on', 'the', 'different', 'literature', 'and', 'the', 'definition', 'of', 'key', 'terms', ',', 'words', 'or', 'phrases', ',', 'keyword', 'extraction', 'is', 'a', 'highly', 'related', 'theme', '.', '\\n\\n', 'Supervised', 'learning', 'approaches', '\\n', 'Beginning', 'with', 'the', 'work', 'of', 'Turney,[11', ']', 'many', 'researchers', 'have', 'approached', 'keyphrase', 'extraction', 'as', 'a', 'supervised', 'machine', 'learning', 'problem', '.', 'Given', 'a', 'document', ',', 'we', 'construct', 'an', 'example', 'for', 'each', 'unigram', ',', 'bigram', ',', 'and', 'trigram', 'found', 'in', 'the', 'text', '(', 'though', 'other', 'text', 'units', 'are', 'also', 'possible', ',', 'as', 'discussed', 'below', ')', '.', 'We', 'then', 'compute', 'various', 'features', 'describing', 'each', 'example', '(', 'e.g.', ',', 'does', 'the', 'phrase', 'begin', 'with', 'an', 'upper', '-', 'case', 'letter', '?', ')', '.', 'We', 'assume', 'there', 'are', 'known', 'keyphrases', 'available', 'for', 'a', 'set', 'of', 'training', 'documents', '.', 'Using', 'the', 'known', 'keyphrases', ',', 'we', 'can', 'assign', 'positive', 'or', 'negative', 'labels', 'to', 'the', 'examples', '.', 'Then', 'we', 'learn', 'a', 'classifier', 'that', 'can', 'discriminate', 'between', 'positive', 'and', 'negative', 'examples', 'as', 'a', 'function', 'of', 'the', 'features', '.', 'Some', 'classifiers', 'make', 'a', 'binary', 'classification', 'for', 'a', 'test', 'example', ',', 'while', 'others', 'assign', 'a', 'probability', 'of', 'being', 'a', 'keyphrase', '.', 'For', 'instance', ',', 'in', 'the', 'above', 'text', ',', 'we', 'might', 'learn', 'a', 'rule', 'that', 'says', 'phrases', 'with', 'initial', 'capital', 'letters', 'are', 'likely', 'to', 'be', 'keyphrases', '.', 'After', 'training', 'a', 'learner', ',', 'we', 'can', 'select', 'keyphrases', 'for', 'test', 'documents', 'in', 'the', 'following', 'manner', '.', 'We', 'apply', 'the', 'same', 'example', '-', 'generation', 'strategy', 'to', 'the', 'test', 'documents', ',', 'then', 'run', 'each', 'example', 'through', 'the', 'learner', '.', 'We', 'can', 'determine', 'the', 'keyphrases', 'by', 'looking', 'at', 'binary', 'classification', 'decisions', 'or', 'probabilities', 'returned', 'from', 'our', 'learned', 'model', '.', 'If', 'probabilities', 'are', 'given', ',', 'a', 'threshold', 'is', 'used', 'to', 'select', 'the', 'keyphrases', '.', 'Keyphrase', 'extractors', 'are', 'generally', 'evaluated', 'using', 'precision', 'and', 'recall', '.', 'Precision', 'measures', 'how', 'many', 'of', 'the', 'proposed', 'keyphrases', 'are', 'actually', 'correct', '.', 'Recall', 'measures', 'how', 'many', 'of', 'the', 'true', 'keyphrases', 'your', 'system', 'proposed', '.', 'The', 'two', 'measures', 'can', 'be', 'combined', 'in', 'an', 'F', '-', 'score', ',', 'which', 'is', 'the', 'harmonic', 'mean', 'of', 'the', 'two', '(', 'F', '=', '2PR/(P', '+', 'R', ')', ')', '.', 'Matches', 'between', 'the', 'proposed', 'keyphrases', 'and', 'the', 'known', 'keyphrases', 'can', 'be', 'checked', 'after', 'stemming', 'or', 'applying', 'some', 'other', 'text', 'normalization', '.', '\\n\\n', 'Designing', 'a', 'supervised', 'keyphrase', 'extraction', 'system', 'involves', 'deciding', 'on', 'several', 'choices', '(', 'some', 'of', 'these', 'apply', 'to', 'unsupervised', ',', 'too', ')', '.', 'The', 'first', 'choice', 'is', 'exactly', 'how', 'to', 'generate', 'examples', '.', 'Turney', 'and', 'others', 'have', 'used', 'all', 'possible', 'unigrams', ',', 'bigrams', ',', 'and', 'trigrams', 'without', 'intervening', 'punctuation', 'and', 'after', 'removing', 'stopwords', '.', 'Hulth', 'showed', 'that', 'you', 'can', 'get', 'some', 'improvement', 'by', 'selecting', 'examples', 'to', 'be', 'sequences', 'of', 'tokens', 'that', 'match', 'certain', 'patterns', 'of', 'part', '-', 'of', '-', 'speech', 'tags', '.', 'Ideally', ',', 'the', 'mechanism', 'for', 'generating', 'examples', 'produces', 'all', 'the', 'known', 'labeled', 'keyphrases', 'as', 'candidates', ',', 'though', 'this', 'is', 'often', 'not', 'the', 'case', '.', 'For', 'example', ',', 'if', 'we', 'use', 'only', 'unigrams', ',', 'bigrams', ',', 'and', 'trigrams', ',', 'then', 'we', 'will', 'never', 'be', 'able', 'to', 'extract', 'a', 'known', 'keyphrase', 'containing', 'four', 'words', '.', 'Thus', ',', 'recall', 'may', 'suffer', '.', 'However', ',', 'generating', 'too', 'many', 'examples', 'can', 'also', 'lead', 'to', 'low', 'precision', '.', '\\n\\n', 'We', 'also', 'need', 'to', 'create', 'features', 'that', 'describe', 'the', 'examples', 'and', 'are', 'informative', 'enough', 'to', 'allow', 'a', 'learning', 'algorithm', 'to', 'discriminate', 'keyphrases', 'from', 'non-', 'keyphrases', '.', 'Typically', 'features', 'involve', 'various', 'term', 'frequencies', '(', 'how', 'many', 'times', 'a', 'phrase', 'appears', 'in', 'the', 'current', 'text', 'or', 'in', 'a', 'larger', 'corpus', ')', ',', 'the', 'length', 'of', 'the', 'example', ',', 'relative', 'position', 'of', 'the', 'first', 'occurrence', ',', 'various', 'boolean', 'syntactic', 'features', '(', 'e.g.', ',', 'contains', 'all', 'caps', ')', ',', 'etc', '.', 'The', 'Turney', 'paper', 'used', 'about', '12', 'such', 'features', '.', 'Hulth', 'uses', 'a', 'reduced', 'set', 'of', 'features', ',', 'which', 'were', 'found', 'most', 'successful', 'in', 'the', 'KEA', '(', 'Keyphrase', 'Extraction', 'Algorithm', ')', 'work', 'derived', 'from', 'Turney', \"'s\", 'seminal', 'paper', '.', '\\n\\n', 'In', 'the', 'end', ',', 'the', 'system', 'will', 'need', 'to', 'return', 'a', 'list', 'of', 'keyphrases', 'for', 'a', 'test', 'document', ',', 'so', 'we', 'need', 'to', 'have', 'a', 'way', 'to', 'limit', 'the', 'number', '.', 'Ensemble', 'methods', '(', 'i.e.', ',', 'using', 'votes', 'from', 'several', 'classifiers', ')', 'have', 'been', 'used', 'to', 'produce', 'numeric', 'scores', 'that', 'can', 'be', 'thresholded', 'to', 'provide', 'a', 'user', '-', 'provided', 'number', 'of', 'keyphrases', '.', 'This', 'is', 'the', 'technique', 'used', 'by', 'Turney', 'with', 'C4.5', 'decision', 'trees', '.', 'Hulth', 'used', 'a', 'single', 'binary', 'classifier', 'so', 'the', 'learning', 'algorithm', 'implicitly', 'determines', 'the', 'appropriate', 'number', '.', '\\n\\n', 'Once', 'examples', 'and', 'features', 'are', 'created', ',', 'we', 'need', 'a', 'way', 'to', 'learn', 'to', 'predict', 'keyphrases', '.', 'Virtually', 'any', 'supervised', 'learning', 'algorithm', 'could', 'be', 'used', ',', 'such', 'as', 'decision', 'trees', ',', 'Naive', 'Bayes', ',', 'and', 'rule', 'induction', '.', 'In', 'the', 'case', 'of', 'Turney', \"'s\", 'GenEx', 'algorithm', ',', 'a', 'genetic', 'algorithm', 'is', 'used', 'to', 'learn', 'parameters', 'for', 'a', 'domain', '-', 'specific', 'keyphrase', 'extraction', 'algorithm', '.', 'The', 'extractor', 'follows', 'a', 'series', 'of', 'heuristics', 'to', 'identify', 'keyphrases', '.', 'The', 'genetic', 'algorithm', 'optimizes', 'parameters', 'for', 'these', 'heuristics', 'with', 'respect', 'to', 'performance', 'on', 'training', 'documents', 'with', 'known', 'key', 'phrases', '.', '\\n\\n', 'Unsupervised', 'approach', ':', 'TextRank', '\\n', 'Another', 'keyphrase', 'extraction', 'algorithm', 'is', 'TextRank', '.', 'While', 'supervised', 'methods', 'have', 'some', 'nice', 'properties', ',', 'like', 'being', 'able', 'to', 'produce', 'interpretable', 'rules', 'for', 'what', 'features', 'characterize', 'a', 'keyphrase', ',', 'they', 'also', 'require', 'a', 'large', 'amount', 'of', 'training', 'data', '.', 'Many', 'documents', 'with', 'known', 'keyphrases', 'are', 'needed', '.', 'Furthermore', ',', 'training', 'on', 'a', 'specific', 'domain', 'tends', 'to', 'customize', 'the', 'extraction', 'process', 'to', 'that', 'domain', ',', 'so', 'the', 'resulting', 'classifier', 'is', 'not', 'necessarily', 'portable', ',', 'as', 'some', 'of', 'Turney', \"'s\", 'results', 'demonstrate', '.', 'Unsupervised', 'keyphrase', 'extraction', 'removes', 'the', 'need', 'for', 'training', 'data', '.', 'It', 'approaches', 'the', 'problem', 'from', 'a', 'different', 'angle', '.', 'Instead', 'of', 'trying', 'to', 'learn', 'explicit', 'features', 'that', 'characterize', 'keyphrases', ',', 'the', 'TextRank', 'algorithm[12', ']', 'exploits', 'the', 'structure', 'of', 'the', 'text', 'itself', 'to', 'determine', 'keyphrases', 'that', 'appear', '\"', 'central', '\"', 'to', 'the', 'text', 'in', 'the', 'same', 'way', 'that', 'PageRank', 'selects', 'important', 'Web', 'pages', '.', 'Recall', 'this', 'is', 'based', 'on', 'the', 'notion', 'of', '\"', 'prestige', '\"', 'or', '\"', 'recommendation', '\"', 'from', 'social', 'networks', '.', 'In', 'this', 'way', ',', 'TextRank', 'does', 'not', 'rely', 'on', 'any', 'previous', 'training', 'data', 'at', 'all', ',', 'but', 'rather', 'can', 'be', 'run', 'on', 'any', 'arbitrary', 'piece', 'of', 'text', ',', 'and', 'it', 'can', 'produce', 'output', 'simply', 'based', 'on', 'the', 'text', \"'s\", 'intrinsic', 'properties', '.', 'Thus', 'the', 'algorithm', 'is', 'easily', 'portable', 'to', 'new', 'domains', 'and', 'languages', '.', '\\n\\n', 'TextRank', 'is', 'a', 'general', 'purpose', 'graph', '-', 'based', 'ranking', 'algorithm', 'for', 'NLP', '.', 'Essentially', ',', 'it', 'runs', 'PageRank', 'on', 'a', 'graph', 'specially', 'designed', 'for', 'a', 'particular', 'NLP', 'task', '.', 'For', 'keyphrase', 'extraction', ',', 'it', 'builds', 'a', 'graph', 'using', 'some', 'set', 'of', 'text', 'units', 'as', 'vertices', '.', 'Edges', 'are', 'based', 'on', 'some', 'measure', 'of', 'semantic', 'or', 'lexical', 'similarity', 'between', 'the', 'text', 'unit', 'vertices', '.', 'Unlike', 'PageRank', ',', 'the', 'edges', 'are', 'typically', 'undirected', 'and', 'can', 'be', 'weighted', 'to', 'reflect', 'a', 'degree', 'of', 'similarity', '.', 'Once', 'the', 'graph', 'is', 'constructed', ',', 'it', 'is', 'used', 'to', 'form', 'a', 'stochastic', 'matrix', ',', 'combined', 'with', 'a', 'damping', 'factor', '(', 'as', 'in', 'the', '\"', 'random', 'surfer', 'model', '\"', ')', ',', 'and', 'the', 'ranking', 'over', 'vertices', 'is', 'obtained', 'by', 'finding', 'the', 'eigenvector', 'corresponding', 'to', 'eigenvalue', '1', '(', 'i.e.', ',', 'the', 'stationary', 'distribution', 'of', 'the', 'random', 'walk', 'on', 'the', 'graph', ')', '.', '\\n\\n', 'The', 'vertices', 'should', 'correspond', 'to', 'what', 'we', 'want', 'to', 'rank', '.', 'Potentially', ',', 'we', 'could', 'do', 'something', 'similar', 'to', 'the', 'supervised', 'methods', 'and', 'create', 'a', 'vertex', 'for', 'each', 'unigram', ',', 'bigram', ',', 'trigram', ',', 'etc', '.', 'However', ',', 'to', 'keep', 'the', 'graph', 'small', ',', 'the', 'authors', 'decide', 'to', 'rank', 'individual', 'unigrams', 'in', 'a', 'first', 'step', ',', 'and', 'then', 'include', 'a', 'second', 'step', 'that', 'merges', 'highly', 'ranked', 'adjacent', 'unigrams', 'to', 'form', 'multi', '-', 'word', 'phrases', '.', 'This', 'has', 'a', 'nice', 'side', 'effect', 'of', 'allowing', 'us', 'to', 'produce', 'keyphrases', 'of', 'arbitrary', 'length', '.', 'For', 'example', ',', 'if', 'we', 'rank', 'unigrams', 'and', 'find', 'that', '\"', 'advanced', '\"', ',', '\"', 'natural', '\"', ',', '\"', 'language', '\"', ',', 'and', '\"', 'processing', '\"', 'all', 'get', 'high', 'ranks', ',', 'then', 'we', 'would', 'look', 'at', 'the', 'original', 'text', 'and', 'see', 'that', 'these', 'words', 'appear', 'consecutively', 'and', 'create', 'a', 'final', 'keyphrase', 'using', 'all', 'four', 'together', '.', 'Note', 'that', 'the', 'unigrams', 'placed', 'in', 'the', 'graph', 'can', 'be', 'filtered', 'by', 'part', 'of', 'speech', '.', 'The', 'authors', 'found', 'that', 'adjectives', 'and', 'nouns', 'were', 'the', 'best', 'to', 'include', '.', 'Thus', ',', 'some', 'linguistic', 'knowledge', 'comes', 'into', 'play', 'in', 'this', 'step', '.', '\\n\\n', 'Edges', 'are', 'created', 'based', 'on', 'word', 'co', '-', 'occurrence', 'in', 'this', 'application', 'of', 'TextRank', '.', 'Two', 'vertices', 'are', 'connected', 'by', 'an', 'edge', 'if', 'the', 'unigrams', 'appear', 'within', 'a', 'window', 'of', 'size', 'N', 'in', 'the', 'original', 'text', '.', 'N', 'is', 'typically', 'around', '2–10', '.', 'Thus', ',', '\"', 'natural', '\"', 'and', '\"', 'language', '\"', 'might', 'be', 'linked', 'in', 'a', 'text', 'about', 'NLP', '.', '\"', 'Natural', '\"', 'and', '\"', 'processing', '\"', 'would', 'also', 'be', 'linked', 'because', 'they', 'would', 'both', 'appear', 'in', 'the', 'same', 'string', 'of', 'N', 'words', '.', 'These', 'edges', 'build', 'on', 'the', 'notion', 'of', '\"', 'text', 'cohesion', '\"', 'and', 'the', 'idea', 'that', 'words', 'that', 'appear', 'near', 'each', 'other', 'are', 'likely', 'related', 'in', 'a', 'meaningful', 'way', 'and', '\"', 'recommend', '\"', 'each', 'other', 'to', 'the', 'reader', '.', '\\n\\n', 'Since', 'this', 'method', 'simply', 'ranks', 'the', 'individual', 'vertices', ',', 'we', 'need', 'a', 'way', 'to', 'threshold', 'or', 'produce', 'a', 'limited', 'number', 'of', 'keyphrases', '.', 'The', 'technique', 'chosen', 'is', 'to', 'set', 'a', 'count', 'T', 'to', 'be', 'a', 'user', '-', 'specified', 'fraction', 'of', 'the', 'total', 'number', 'of', 'vertices', 'in', 'the', 'graph', '.', 'Then', 'the', 'top', 'T', 'vertices', '/', 'unigrams', 'are', 'selected', 'based', 'on', 'their', 'stationary', 'probabilities', '.', 'A', 'post-', 'processing', 'step', 'is', 'then', 'applied', 'to', 'merge', 'adjacent', 'instances', 'of', 'these', 'T', 'unigrams', '.', 'As', 'a', 'result', ',', 'potentially', 'more', 'or', 'less', 'than', 'T', 'final', 'keyphrases', 'will', 'be', 'produced', ',', 'but', 'the', 'number', 'should', 'be', 'roughly', 'proportional', 'to', 'the', 'length', 'of', 'the', 'original', 'text', '.', '\\n\\n', 'It', 'is', 'not', 'initially', 'clear', 'why', 'applying', 'PageRank', 'to', 'a', 'co', '-', 'occurrence', 'graph', 'would', 'produce', 'useful', 'keyphrases', '.', 'One', 'way', 'to', 'think', 'about', 'it', 'is', 'the', 'following', '.', 'A', 'word', 'that', 'appears', 'multiple', 'times', 'throughout', 'a', 'text', 'may', 'have', 'many', 'different', 'co', '-', 'occurring', 'neighbors', '.', 'For', 'example', ',', 'in', 'a', 'text', 'about', 'machine', 'learning', ',', 'the', 'unigram', '\"', 'learning', '\"', 'might', 'co', '-', 'occur', 'with', '\"', 'machine', '\"', ',', '\"', 'supervised', '\"', ',', '\"', 'un', '-', 'supervised', '\"', ',', 'and', '\"', 'semi', '-', 'supervised', '\"', 'in', 'four', 'different', 'sentences', '.', 'Thus', ',', 'the', '\"', 'learning', '\"', 'vertex', 'would', 'be', 'a', 'central', '\"', 'hub', '\"', 'that', 'connects', 'to', 'these', 'other', 'modifying', 'words', '.', 'Running', 'PageRank', '/', 'TextRank', 'on', 'the', 'graph', 'is', 'likely', 'to', 'rank', '\"', 'learning', '\"', 'highly', '.', 'Similarly', ',', 'if', 'the', 'text', 'contains', 'the', 'phrase', '\"', 'supervised', 'classification', '\"', ',', 'then', 'there', 'would', 'be', 'an', 'edge', 'between', '\"', 'supervised', '\"', 'and', '\"', 'classification', '\"', '.', 'If', '\"', 'classification', '\"', 'appears', 'several', 'other', 'places', 'and', 'thus', 'has', 'many', 'neighbors', ',', 'its', 'importance', 'would', 'contribute', 'to', 'the', 'importance', 'of', '\"', 'supervised', '\"', '.', 'If', 'it', 'ends', 'up', 'with', 'a', 'high', 'rank', ',', 'it', 'will', 'be', 'selected', 'as', 'one', 'of', 'the', 'top', 'T', 'unigrams', ',', 'along', 'with', '\"', 'learning', '\"', 'and', 'probably', '\"', 'classification', '\"', '.', 'In', 'the', 'final', 'post', '-', 'processing', 'step', ',', 'we', 'would', 'then', 'end', 'up', 'with', 'keyphrases', '\"', 'supervised', 'learning', '\"', 'and', '\"', 'supervised', 'classification', '\"', '.', '\\n\\n', 'In', 'short', ',', 'the', 'co', '-', 'occurrence', 'graph', 'will', 'contain', 'densely', 'connected', 'regions', 'for', 'terms', 'that', 'appear', 'often', 'and', 'in', 'different', 'contexts', '.', 'A', 'random', 'walk', 'on', 'this', 'graph', 'will', 'have', 'a', 'stationary', 'distribution', 'that', 'assigns', 'large', 'probabilities', 'to', 'the', 'terms', 'in', 'the', 'centers', 'of', 'the', 'clusters', '.', 'This', 'is', 'similar', 'to', 'densely', 'connected', 'Web', 'pages', 'getting', 'ranked', 'highly', 'by', 'PageRank', '.', 'This', 'approach', 'has', 'also', 'been', 'used', 'in', 'document', 'summarization', ',', 'considered', 'below', '.', '\\n\\n', 'Document', 'summarization', '\\n', 'Like', 'keyphrase', 'extraction', ',', 'document', 'summarization', 'aims', 'to', 'identify', 'the', 'essence', 'of', 'a', 'text', '.', 'The', 'only', 'real', 'difference', 'is', 'that', 'now', 'we', 'are', 'dealing', 'with', 'larger', 'text', 'units', '—', 'whole', 'sentences', 'instead', 'of', 'words', 'and', 'phrases', '.', '\\n\\n', 'Before', 'getting', 'into', 'the', 'details', 'of', 'some', 'summarization', 'methods', ',', 'we', 'will', 'mention', 'how', 'summarization', 'systems', 'are', 'typically', 'evaluated', '.', 'The', 'most', 'common', 'way', 'is', 'using', 'the', 'so', '-', 'called', 'ROUGE', '(', 'Recall', '-', 'Oriented', 'Understudy', 'for', 'Gisting', 'Evaluation', ')', 'measure', '.', 'This', 'is', 'a', 'recall', '-', 'based', 'measure', 'that', 'determines', 'how', 'well', 'a', 'system', '-', 'generated', 'summary', 'covers', 'the', 'content', 'present', 'in', 'one', 'or', 'more', 'human', '-', 'generated', 'model', 'summaries', 'known', 'as', 'references', '.', 'It', 'is', 'recall', '-', 'based', 'to', 'encourage', 'systems', 'to', 'include', 'all', 'the', 'important', 'topics', 'in', 'the', 'text', '.', 'Recall', 'can', 'be', 'computed', 'with', 'respect', 'to', 'unigram', ',', 'bigram', ',', 'trigram', ',', 'or', '4-gram', 'matching', '.', 'For', 'example', ',', 'ROUGE-1', 'is', 'computed', 'as', 'division', 'of', 'count', 'of', 'unigrams', 'in', 'reference', 'that', 'appear', 'in', 'system', 'and', 'count', 'of', 'unigrams', 'in', 'reference', 'summary', '.', '\\n\\n', 'If', 'there', 'are', 'multiple', 'references', ',', 'the', 'ROUGE-1', 'scores', 'are', 'averaged', '.', 'Because', 'ROUGE', 'is', 'based', 'only', 'on', 'content', 'overlap', ',', 'it', 'can', 'determine', 'if', 'the', 'same', 'general', 'concepts', 'are', 'discussed', 'between', 'an', 'automatic', 'summary', 'and', 'a', 'reference', 'summary', ',', 'but', 'it', 'can', 'not', 'determine', 'if', 'the', 'result', 'is', 'coherent', 'or', 'the', 'sentences', 'flow', 'together', 'in', 'a', 'sensible', 'manner', '.', 'High', '-', 'order', 'n', '-', 'gram', 'ROUGE', 'measures', 'try', 'to', 'judge', 'fluency', 'to', 'some', 'degree', '.', 'Note', 'that', 'ROUGE', 'is', 'similar', 'to', 'the', 'BLEU', 'measure', 'for', 'machine', 'translation', ',', 'but', 'BLEU', 'is', 'precision-', 'based', ',', 'because', 'translation', 'systems', 'favor', 'accuracy', '.', '\\n\\n', 'A', 'promising', 'line', 'in', 'document', 'summarization', 'is', 'adaptive', 'document', '/', 'text', 'summarization.[13', ']', 'The', 'idea', 'of', 'adaptive', 'summarization', 'involves', 'preliminary', 'recognition', 'of', 'document', '/', 'text', 'genre', 'and', 'subsequent', 'application', 'of', 'summarization', 'algorithms', 'optimized', 'for', 'this', 'genre', '.', 'First', 'summarizes', 'that', 'perform', 'adaptive', 'summarization', 'have', 'been', 'created.[14', ']', '\\n\\n', 'Supervised', 'learning', 'approaches', '\\n', 'Supervised', 'text', 'summarization', 'is', 'very', 'much', 'like', 'supervised', 'keyphrase', 'extraction', '.', 'Basically', ',', 'if', 'you', 'have', 'a', 'collection', 'of', 'documents', 'and', 'human', '-', 'generated', 'summaries', 'for', 'them', ',', 'you', 'can', 'learn', 'features', 'of', 'sentences', 'that', 'make', 'them', 'good', 'candidates', 'for', 'inclusion', 'in', 'the', 'summary', '.', 'Features', 'might', 'include', 'the', 'position', 'in', 'the', 'document', '(', 'i.e.', ',', 'the', 'first', 'few', 'sentences', 'are', 'probably', 'important', ')', ',', 'the', 'number', 'of', 'words', 'in', 'the', 'sentence', ',', 'etc', '.', 'The', 'main', 'difficulty', 'in', 'supervised', 'extractive', 'summarization', 'is', 'that', 'the', 'known', 'summaries', 'must', 'be', 'manually', 'created', 'by', 'extracting', 'sentences', 'so', 'the', 'sentences', 'in', 'an', 'original', 'training', 'document', 'can', 'be', 'labeled', 'as', '\"', 'in', 'summary', '\"', 'or', '\"', 'not', 'in', 'summary', '\"', '.', 'This', 'is', 'not', 'typically', 'how', 'people', 'create', 'summaries', ',', 'so', 'simply', 'using', 'journal', 'abstracts', 'or', 'existing', 'summaries', 'is', 'usually', 'not', 'sufficient', '.', 'The', 'sentences', 'in', 'these', 'summaries', 'do', 'not', 'necessarily', 'match', 'up', 'with', 'sentences', 'in', 'the', 'original', 'text', ',', 'so', 'it', 'would', 'be', 'difficult', 'to', 'assign', 'labels', 'to', 'examples', 'for', 'training', '.', 'Note', ',', 'however', ',', 'that', 'these', 'natural', 'summaries', 'can', 'still', 'be', 'used', 'for', 'evaluation', 'purposes', ',', 'since', 'ROUGE-1', 'only', 'cares', 'about', 'unigrams', '.', '\\n\\n', 'Maximum', 'entropy', '-', 'based', 'summarization', '\\n', 'During', 'the', 'DUC', '2001', 'and', '2002', 'evaluation', 'workshops', ',', 'TNO', 'developed', 'a', 'sentence', 'extraction', 'system', 'for', 'multi', '-', 'document', 'summarization', 'in', 'the', 'news', 'domain', '.', 'The', 'system', 'was', 'based', 'on', 'a', 'hybrid', 'system', 'using', 'a', 'naive', 'Bayes', 'classifier', 'and', 'statistical', 'language', 'models', 'for', 'modeling', 'salience', '.', 'Although', 'the', 'system', 'exhibited', 'good', 'results', ',', 'the', 'researchers', 'wanted', 'to', 'explore', 'the', 'effectiveness', 'of', 'a', 'maximum', 'entropy', '(', 'ME', ')', 'classifier', 'for', 'the', 'meeting', 'summarization', 'task', ',', 'as', 'ME', 'is', 'known', 'to', 'be', 'robust', 'against', 'feature', 'dependencies', '.', 'Maximum', 'entropy', 'has', 'also', 'been', 'applied', 'successfully', 'for', 'summarization', 'in', 'the', 'broadcast', 'news', 'domain', '.', '\\n\\n', 'TextRank', 'and', 'LexRank', '\\n', 'The', 'unsupervised', 'approach', 'to', 'summarization', 'is', 'also', 'quite', 'similar', 'in', 'spirit', 'to', 'unsupervised', 'keyphrase', 'extraction', 'and', 'gets', 'around', 'the', 'issue', 'of', 'costly', 'training', 'data', '.', 'Some', 'unsupervised', 'summarization', 'approaches', 'are', 'based', 'on', 'finding', 'a', '\"', 'centroid', '\"', 'sentence', ',', 'which', 'is', 'the', 'mean', 'word', 'vector', 'of', 'all', 'the', 'sentences', 'in', 'the', 'document', '.', 'Then', 'the', 'sentences', 'can', 'be', 'ranked', 'with', 'regard', 'to', 'their', 'similarity', 'to', 'this', 'centroid', 'sentence', '.', '\\n\\n', 'A', 'more', 'principled', 'way', 'to', 'estimate', 'sentence', 'importance', 'is', 'using', 'random', 'walks', 'and', 'eigenvector', 'centrality', '.', 'LexRank[15', ']', 'is', 'an', 'algorithm', 'essentially', 'identical', 'to', 'TextRank', ',', 'and', 'both', 'use', 'this', 'approach', 'for', 'document', 'summarization', '.', 'The', 'two', 'methods', 'were', 'developed', 'by', 'different', 'groups', 'at', 'the', 'same', 'time', ',', 'and', 'LexRank', 'simply', 'focused', 'on', 'summarization', ',', 'but', 'could', 'just', 'as', 'easily', 'be', 'used', 'for', 'keyphrase', 'extraction', 'or', 'any', 'other', 'NLP', 'ranking', 'task', '.', '\\n\\n', 'In', 'both', 'LexRank', 'and', 'TextRank', ',', 'a', 'graph', 'is', 'constructed', 'by', 'creating', 'a', 'vertex', 'for', 'each', 'sentence', 'in', 'the', 'document', '.', '\\n\\n', 'The', 'edges', 'between', 'sentences', 'are', 'based', 'on', 'some', 'form', 'of', 'semantic', 'similarity', 'or', 'content', 'overlap', '.', 'While', 'LexRank', 'uses', 'cosine', 'similarity', 'of', 'TF', '-', 'IDF', 'vectors', ',', 'TextRank', 'uses', 'a', 'very', 'similar', 'measure', 'based', 'on', 'the', 'number', 'of', 'words', 'two', 'sentences', 'have', 'in', 'common', '(', 'normalized', 'by', 'the', 'sentences', \"'\", 'lengths', ')', '.', 'The', 'LexRank', 'paper', 'explored', 'using', 'unweighted', 'edges', 'after', 'applying', 'a', 'threshold', 'to', 'the', 'cosine', 'values', ',', 'but', 'also', 'experimented', 'with', 'using', 'edges', 'with', 'weights', 'equal', 'to', 'the', 'similarity', 'score', '.', 'TextRank', 'uses', 'continuous', 'similarity', 'scores', 'as', 'weights', '.', '\\n\\n', 'In', 'both', 'algorithms', ',', 'the', 'sentences', 'are', 'ranked', 'by', 'applying', 'PageRank', 'to', 'the', 'resulting', 'graph', '.', 'A', 'summary', 'is', 'formed', 'by', 'combining', 'the', 'top', 'ranking', 'sentences', ',', 'using', 'a', 'threshold', 'or', 'length', 'cutoff', 'to', 'limit', 'the', 'size', 'of', 'the', 'summary', '.', '\\n\\n', 'It', 'is', 'worth', 'noting', 'that', 'TextRank', 'was', 'applied', 'to', 'summarization', 'exactly', 'as', 'described', 'here', ',', 'while', 'LexRank', 'was', 'used', 'as', 'part', 'of', 'a', 'larger', 'summarization', 'system', '(', 'MEAD', ')', 'that', 'combines', 'the', 'LexRank', 'score', '(', 'stationary', 'probability', ')', 'with', 'other', 'features', 'like', 'sentence', 'position', 'and', 'length', 'using', 'a', 'linear', 'combination', 'with', 'either', 'user', '-', 'specified', 'or', 'automatically', 'tuned', 'weights', '.', 'In', 'this', 'case', ',', 'some', 'training', 'documents', 'might', 'be', 'needed', ',', 'though', 'the', 'TextRank', 'results', 'show', 'the', 'additional', 'features', 'are', 'not', 'absolutely', 'necessary', '.', '\\n\\n', 'Another', 'important', 'distinction', 'is', 'that', 'TextRank', 'was', 'used', 'for', 'single', 'document', 'summarization', ',', 'while', 'LexRank', 'has', 'been', 'applied', 'to', 'multi', '-', 'document', 'summarization', '.', 'The', 'task', 'remains', 'the', 'same', 'in', 'both', 'cases', '—', 'only', 'the', 'number', 'of', 'sentences', 'to', 'choose', 'from', 'has', 'grown', '.', 'However', ',', 'when', 'summarizing', 'multiple', 'documents', ',', 'there', 'is', 'a', 'greater', 'risk', 'of', 'selecting', 'duplicate', 'or', 'highly', 'redundant', 'sentences', 'to', 'place', 'in', 'the', 'same', 'summary', '.', 'Imagine', 'you', 'have', 'a', 'cluster', 'of', 'news', 'articles', 'on', 'a', 'particular', 'event', ',', 'and', 'you', 'want', 'to', 'produce', 'one', 'summary', '.', 'Each', 'article', 'is', 'likely', 'to', 'have', 'many', 'similar', 'sentences', ',', 'and', 'you', 'would', 'only', 'want', 'to', 'include', 'distinct', 'ideas', 'in', 'the', 'summary', '.', 'To', 'address', 'this', 'issue', ',', 'LexRank', 'applies', 'a', 'heuristic', 'post', '-', 'processing', 'step', 'that', 'builds', 'up', 'a', 'summary', 'by', 'adding', 'sentences', 'in', 'rank', 'order', ',', 'but', 'discards', 'any', 'sentences', 'that', 'are', 'too', 'similar', 'to', 'ones', 'already', 'placed', 'in', 'the', 'summary', '.', 'The', 'method', 'used', 'is', 'called', 'Cross', '-', 'Sentence', 'Information', 'Subsumption', '(', 'CSIS', ')', '.', '\\n\\n', 'These', 'methods', 'work', 'based', 'on', 'the', 'idea', 'that', 'sentences', '\"', 'recommend', '\"', 'other', 'similar', 'sentences', 'to', 'the', 'reader', '.', 'Thus', ',', 'if', 'one', 'sentence', 'is', 'very', 'similar', 'to', 'many', 'others', ',', 'it', 'will', 'likely', 'be', 'a', 'sentence', 'of', 'great', 'importance', '.', 'The', 'importance', 'of', 'this', 'sentence', 'also', 'stems', 'from', 'the', 'importance', 'of', 'the', 'sentences', '\"', 'recommending', '\"', 'it', '.', 'Thus', ',', 'to', 'get', 'ranked', 'highly', 'and', 'placed', 'in', 'a', 'summary', ',', 'a', 'sentence', 'must', 'be', 'similar', 'to', 'many', 'sentences', 'that', 'are', 'in', 'turn', 'also', 'similar', 'to', 'many', 'other', 'sentences', '.', 'This', 'makes', 'intuitive', 'sense', 'and', 'allows', 'the', 'algorithms', 'to', 'be', 'applied', 'to', 'any', 'arbitrary', 'new', 'text', '.', 'The', 'methods', 'are', 'domain', '-', 'independent', 'and', 'easily', 'portable', '.', 'One', 'could', 'imagine', 'the', 'features', 'indicating', 'important', 'sentences', 'in', 'the', 'news', 'domain', 'might', 'vary', 'considerably', 'from', 'the', 'biomedical', 'domain', '.', 'However', ',', 'the', 'unsupervised', '\"', 'recommendation\"-based', 'approach', 'applies', 'to', 'any', 'domain', '.', '\\n\\n', 'Multi', '-', 'document', 'summarization', '\\n', 'Main', 'article', ':', 'Multi', '-', 'document', 'summarization', '\\n', 'Multi', '-', 'document', 'summarization', 'is', 'an', 'automatic', 'procedure', 'aimed', 'at', 'extraction', 'of', 'information', 'from', 'multiple', 'texts', 'written', 'about', 'the', 'same', 'topic', '.', 'Resulting', 'summary', 'report', 'allows', 'individual', 'users', ',', 'such', 'as', 'professional', 'information', 'consumers', ',', 'to', 'quickly', 'familiarize', 'themselves', 'with', 'information', 'contained', 'in', 'a', 'large', 'cluster', 'of', 'documents', '.', 'In', 'such', 'a', 'way', ',', 'multi', '-', 'document', 'summarization', 'systems', 'are', 'complementing', 'the', 'news', 'aggregators', 'performing', 'the', 'next', 'step', 'down', 'the', 'road', 'of', 'coping', 'with', 'information', 'overload', '.', 'Multi', '-', 'document', 'summarization', 'may', 'also', 'be', 'done', 'in', 'response', 'to', 'a', 'question.[16][8', ']', '\\n\\n', 'Multi', '-', 'document', 'summarization', 'creates', 'information', 'reports', 'that', 'are', 'both', 'concise', 'and', 'comprehensive', '.', 'With', 'different', 'opinions', 'being', 'put', 'together', 'and', 'outlined', ',', 'every', 'topic', 'is', 'described', 'from', 'multiple', 'perspectives', 'within', 'a', 'single', 'document', '.', 'While', 'the', 'goal', 'of', 'a', 'brief', 'summary', 'is', 'to', 'simplify', 'information', 'search', 'and', 'cut', 'the', 'time', 'by', 'pointing', 'to', 'the', 'most', 'relevant', 'source', 'documents', ',', 'comprehensive', 'multi', '-', 'document', 'summary', 'should', 'itself', 'contain', 'the', 'required', 'information', ',', 'hence', 'limiting', 'the', 'need', 'for', 'accessing', 'original', 'files', 'to', 'cases', 'when', 'refinement', 'is', 'required', '.', 'Automatic', 'summaries', 'present', 'information', 'extracted', 'from', 'multiple', 'sources', 'algorithmically', ',', 'without', 'any', 'editorial', 'touch', 'or', 'subjective', 'human', 'intervention', ',', 'thus', 'making', 'it', 'completely', 'unbiased.[dubious', '–', 'discuss', ']', '\\n\\n', 'Incorporating', 'diversity', '\\n', 'Multi', '-', 'document', 'extractive', 'summarization', 'faces', 'a', 'problem', 'of', 'potential', 'redundancy', '.', 'Ideally', ',', 'we', 'would', 'like', 'to', 'extract', 'sentences', 'that', 'are', 'both', '\"', 'central', '\"', '(', 'i.e.', ',', 'contain', 'the', 'main', 'ideas', ')', 'and', '\"', 'diverse', '\"', '(', 'i.e.', ',', 'they', 'differ', 'from', 'one', 'another', ')', '.', 'LexRank', 'deals', 'with', 'diversity', 'as', 'a', 'heuristic', 'final', 'stage', 'using', 'CSIS', ',', 'and', 'other', 'systems', 'have', 'used', 'similar', 'methods', ',', 'such', 'as', 'Maximal', 'Marginal', 'Relevance', '(', 'MMR),[17', ']', 'in', 'trying', 'to', 'eliminate', 'redundancy', 'in', 'information', 'retrieval', 'results', '.', 'There', 'is', 'a', 'general', 'purpose', 'graph', '-', 'based', 'ranking', 'algorithm', 'like', 'Page', '/', 'Lex', '/', 'TextRank', 'that', 'handles', 'both', '\"', 'centrality', '\"', 'and', '\"', 'diversity', '\"', 'in', 'a', 'unified', 'mathematical', 'framework', 'based', 'on', 'absorbing', 'Markov', 'chain', 'random', 'walks', '.', '(', 'An', 'absorbing', 'random', 'walk', 'is', 'like', 'a', 'standard', 'random', 'walk', ',', 'except', 'some', 'states', 'are', 'now', 'absorbing', 'states', 'that', 'act', 'as', '\"', 'black', 'holes', '\"', 'that', 'cause', 'the', 'walk', 'to', 'end', 'abruptly', 'at', 'that', 'state', '.', ')', 'The', 'algorithm', 'is', 'called', 'GRASSHOPPER.[18', ']', 'In', 'addition', 'to', 'explicitly', 'promoting', 'diversity', 'during', 'the', 'ranking', 'process', ',', 'GRASSHOPPER', 'incorporates', 'a', 'prior', 'ranking', '(', 'based', 'on', 'sentence', 'position', 'in', 'the', 'case', 'of', 'summarization', ')', '.', '\\n\\n', 'The', 'state', 'of', 'the', 'art', 'results', 'for', 'multi', '-', 'document', 'summarization', ',', 'however', ',', 'are', 'obtained', 'using', 'mixtures', 'of', 'submodular', 'functions', '.', 'These', 'methods', 'have', 'achieved', 'the', 'state', 'of', 'the', 'art', 'results', 'for', 'Document', 'Summarization', 'Corpora', ',', 'DUC', '04', '-', '07.[19', ']', 'Similar', 'results', 'were', 'also', 'achieved', 'with', 'the', 'use', 'of', 'determinantal', 'point', 'processes', '(', 'which', 'are', 'a', 'special', 'case', 'of', 'submodular', 'functions', ')', 'for', 'DUC-04.[20', ']', '\\n\\n', 'A', 'new', 'method', 'for', 'multi', '-', 'lingual', 'multi', '-', 'document', 'summarization', 'that', 'avoids', 'redundancy', 'works', 'by', 'simplifying', 'and', 'generating', 'ideograms', 'that', 'represent', 'the', 'meaning', 'of', 'each', 'sentence', 'in', 'each', 'document', 'and', 'then', 'evaluates', 'similarity', '\"', 'qualitatively', '\"', 'by', 'comparing', 'the', 'shape', 'and', 'position', 'of', 'said', 'ideograms', 'has', 'recently', 'been', 'developed', '.', 'This', 'tool', 'does', 'not', 'use', 'word', 'frequency', ',', 'does', 'not', 'need', 'training', 'or', 'preprocessing', 'of', 'any', 'kind', 'and', 'works', 'by', 'generating', 'ideograms', 'that', 'represent', 'the', 'meaning', 'of', 'each', 'sentence', 'and', 'then', 'summarizes', 'using', 'two', 'user', '-', 'supplied', 'parameters', ':', 'equivalence', '(', 'when', 'are', 'two', 'sentences', 'to', 'be', 'considered', 'equivalent', ')', 'and', 'relevance', '(', 'how', 'long', 'is', 'the', 'desired', 'summary', ')', '.', '\\n\\n', 'Submodular', 'functions', 'as', 'generic', 'tools', 'for', 'summarization', '\\n', 'The', 'idea', 'of', 'a', 'submodular', 'set', 'function', 'has', 'recently', 'emerged', 'as', 'a', 'powerful', 'modeling', 'tool', 'for', 'various', 'summarization', 'problems', '.', 'Submodular', 'functions', 'naturally', 'model', 'notions', 'of', 'coverage', ',', 'information', ',', 'representation', 'and', 'diversity', '.', 'Moreover', ',', 'several', 'important', 'combinatorial', 'optimization', 'problems', 'occur', 'as', 'special', 'instances', 'of', 'submodular', 'optimization', '.', 'For', 'example', ',', 'the', 'set', 'cover', 'problem', 'is', 'a', 'special', 'case', 'of', 'submodular', 'optimization', ',', 'since', 'the', 'set', 'cover', 'function', 'is', 'submodular', '.', 'The', 'set', 'cover', 'function', 'attempts', 'to', 'find', 'a', 'subset', 'of', 'objects', 'which', 'cover', 'a', 'given', 'set', 'of', 'concepts', '.', 'For', 'example', ',', 'in', 'document', 'summarization', ',', 'one', 'would', 'like', 'the', 'summary', 'to', 'cover', 'all', 'important', 'and', 'relevant', 'concepts', 'in', 'the', 'document', '.', 'This', 'is', 'an', 'instance', 'of', 'set', 'cover', '.', 'Similarly', ',', 'the', 'facility', 'location', 'problem', 'is', 'a', 'special', 'case', 'of', 'submodular', 'functions', '.', 'The', 'Facility', 'Location', 'function', 'also', 'naturally', 'models', 'coverage', 'and', 'diversity', '.', 'Another', 'example', 'of', 'a', 'submodular', 'optimization', 'problem', 'is', 'using', 'a', 'determinantal', 'point', 'process', 'to', 'model', 'diversity', '.', 'Similarly', ',', 'the', 'Maximum', '-', 'Marginal', '-', 'Relevance', 'procedure', 'can', 'also', 'be', 'seen', 'as', 'an', 'instance', 'of', 'submodular', 'optimization', '.', 'All', 'these', 'important', 'models', 'encouraging', 'coverage', ',', 'diversity', 'and', 'information', 'are', 'all', 'submodular', '.', 'Moreover', ',', 'submodular', 'functions', 'can', 'be', 'efficiently', 'combined', ',', 'and', 'the', 'resulting', 'function', 'is', 'still', 'submodular', '.', 'Hence', ',', 'one', 'could', 'combine', 'one', 'submodular', 'function', 'which', 'models', 'diversity', ',', 'another', 'one', 'which', 'models', 'coverage', 'and', 'use', 'human', 'supervision', 'to', 'learn', 'a', 'right', 'model', 'of', 'a', 'submodular', 'function', 'for', 'the', 'problem', '.', '\\n\\n', 'While', 'submodular', 'functions', 'are', 'fitting', 'problems', 'for', 'summarization', ',', 'they', 'also', 'admit', 'very', 'efficient', 'algorithms', 'for', 'optimization', '.', 'For', 'example', ',', 'a', 'simple', 'greedy', 'algorithm', 'admits', 'a', 'constant', 'factor', 'guarantee.[21', ']', 'Moreover', ',', 'the', 'greedy', 'algorithm', 'is', 'extremely', 'simple', 'to', 'implement', 'and', 'can', 'scale', 'to', 'large', 'datasets', ',', 'which', 'is', 'very', 'important', 'for', 'summarization', 'problems', '.', '\\n\\n', 'Submodular', 'functions', 'have', 'achieved', 'state', '-', 'of', '-', 'the', '-', 'art', 'for', 'almost', 'all', 'summarization', 'problems', '.', 'For', 'example', ',', 'work', 'by', 'Lin', 'and', 'Bilmes', ',', '2012[22', ']', 'shows', 'that', 'submodular', 'functions', 'achieve', 'the', 'best', 'results', 'to', 'date', 'on', 'DUC-04', ',', 'DUC-05', ',', 'DUC-06', 'and', 'DUC-07', 'systems', 'for', 'document', 'summarization', '.', 'Similarly', ',', 'work', 'by', 'Lin', 'and', 'Bilmes', ',', '2011,[23', ']', 'shows', 'that', 'many', 'existing', 'systems', 'for', 'automatic', 'summarization', 'are', 'instances', 'of', 'submodular', 'functions', '.', 'This', 'was', 'a', 'breakthrough', 'result', 'establishing', 'submodular', 'functions', 'as', 'the', 'right', 'models', 'for', 'summarization', 'problems.[citation', 'needed', ']', '\\n\\n', 'Submodular', 'Functions', 'have', 'also', 'been', 'used', 'for', 'other', 'summarization', 'tasks', '.', 'Tschiatschek', 'et', 'al', '.', ',', '2014', 'show[24', ']', 'that', 'mixtures', 'of', 'submodular', 'functions', 'achieve', 'state', '-', 'of', '-', 'the', '-', 'art', 'results', 'for', 'image', 'collection', 'summarization', '.', 'Similarly', ',', 'Bairi', 'et', 'al', '.', ',', '2015[25', ']', 'show', 'the', 'utility', 'of', 'submodular', 'functions', 'for', 'summarizing', 'multi', '-', 'document', 'topic', 'hierarchies', '.', 'Submodular', 'Functions', 'have', 'also', 'successfully', 'been', 'used', 'for', 'summarizing', 'machine', 'learning', 'datasets.[26', ']', '\\n\\n', 'Applications', '\\n', '[', 'icon', ']', '\\t\\n', 'This', 'section', 'needs', 'expansion', '.', 'You', 'can', 'help', 'by', 'adding', 'to', 'it', '.', '(', 'February', '2017', ')', '\\n', 'Specific', 'applications', 'of', 'automatic', 'summarization', 'include', ':', '\\n\\n', 'The', 'Reddit', 'bot', '\"', 'autotldr\",[27', ']', 'created', 'in', '2011', 'summarizes', 'news', 'articles', 'in', 'the', 'comment', '-', 'section', 'of', 'reddit', 'posts', '.', 'It', 'was', 'found', 'to', 'be', 'very', 'useful', 'by', 'the', 'reddit', 'community', 'which', 'upvoted', 'its', 'summaries', 'hundreds', 'of', 'thousands', 'of', 'times.[28', ']', 'The', 'name', 'is', 'reference', 'to', 'TL;DR', '−', 'Internet', 'slang', 'for', '\"', 'too', 'long', ';', 'did', \"n't\", 'read\".[29][30', ']', '\\n', 'Evaluation', 'techniques', '\\n', 'The', 'most', 'common', 'way', 'to', 'evaluate', 'the', 'informativeness', 'of', 'automatic', 'summaries', 'is', 'to', 'compare', 'them', 'with', 'human', '-', 'made', 'model', 'summaries', '.', '\\n\\n', 'Evaluation', 'techniques', 'fall', 'into', 'intrinsic', 'and', 'extrinsic,[31', ']', 'inter', '-', 'textual', 'and', 'intra', '-', 'textual.[32', ']', '\\n\\n', 'Intrinsic', 'and', 'extrinsic', 'evaluation', '\\n', 'An', 'intrinsic', 'evaluation', 'tests', 'the', 'summarization', 'system', 'in', 'and', 'of', 'itself', 'while', 'an', 'extrinsic', 'evaluation', 'tests', 'the', 'summarization', 'based', 'on', 'how', 'it', 'affects', 'the', 'completion', 'of', 'some', 'other', 'task', '.', 'Intrinsic', 'evaluations', 'have', 'assessed', 'mainly', 'the', 'coherence', 'and', 'informativeness', 'of', 'summaries', '.', 'Extrinsic', 'evaluations', ',', 'on', 'the', 'other', 'hand', ',', 'have', 'tested', 'the', 'impact', 'of', 'summarization', 'on', 'tasks', 'like', 'relevance', 'assessment', ',', 'reading', 'comprehension', ',', 'etc', '.', '\\n\\n', 'Inter', '-', 'textual', 'and', 'intra', '-', 'textual', '\\n', 'Intra', '-', 'textual', 'methods', 'assess', 'the', 'output', 'of', 'a', 'specific', 'summarization', 'system', ',', 'and', 'the', 'inter', '-', 'textual', 'ones', 'focus', 'on', 'contrastive', 'analysis', 'of', 'outputs', 'of', 'several', 'summarization', 'systems', '.', '\\n\\n', 'Human', 'judgement', 'often', 'has', 'wide', 'variance', 'on', 'what', 'is', 'considered', 'a', '\"', 'good', '\"', 'summary', ',', 'which', 'means', 'that', 'making', 'the', 'evaluation', 'process', 'automatic', 'is', 'particularly', 'difficult', '.', 'Manual', 'evaluation', 'can', 'be', 'used', ',', 'but', 'this', 'is', 'both', 'time', 'and', 'labor', '-', 'intensive', 'as', 'it', 'requires', 'humans', 'to', 'read', 'not', 'only', 'the', 'summaries', 'but', 'also', 'the', 'source', 'documents', '.', 'Other', 'issues', 'are', 'those', 'concerning', 'coherence', 'and', 'coverage', '.', '\\n\\n', 'One', 'of', 'the', 'metrics', 'used', 'in', 'NIST', \"'s\", 'annual', 'Document', 'Understanding', 'Conferences', ',', 'in', 'which', 'research', 'groups', 'submit', 'their', 'systems', 'for', 'both', 'summarization', 'and', 'translation', 'tasks', ',', 'is', 'the', 'ROUGE', 'metric', '(', 'Recall', '-', 'Oriented', 'Understudy', 'for', 'Gisting', 'Evaluation', '[', '2', ']', ')', '.', 'It', 'essentially', 'calculates', 'n', '-', 'gram', 'overlaps', 'between', 'automatically', 'generated', 'summaries', 'and', 'previously', 'written', 'human', 'summaries', '.', 'A', 'high', 'level', 'of', 'overlap', 'should', 'indicate', 'a', 'high', 'level', 'of', 'shared', 'concepts', 'between', 'the', 'two', 'summaries', '.', 'Note', 'that', 'overlap', 'metrics', 'like', 'this', 'are', 'unable', 'to', 'provide', 'any', 'feedback', 'on', 'a', 'summary', \"'s\", 'coherence', '.', 'Anaphor', 'resolution', 'remains', 'another', 'problem', 'yet', 'to', 'be', 'fully', 'solved', '.', 'Similarly', ',', 'for', 'image', 'summarization', ',', 'Tschiatschek', 'et', 'al', '.', ',', 'developed', 'a', 'Visual', '-', 'ROUGE', 'score', 'which', 'judges', 'the', 'performance', 'of', 'algorithms', 'for', 'image', 'summarization.[33', ']', '\\n\\n', 'Domain', 'specific', 'versus', 'domain', 'independent', 'summarization', 'techniques', '\\n', 'Domain', 'independent', 'summarization', 'techniques', 'generally', 'apply', 'sets', 'of', 'general', 'features', 'which', 'can', 'be', 'used', 'to', 'identify', 'information', '-', 'rich', 'text', 'segments', '.', 'Recent', 'research', 'focus', 'has', 'drifted', 'to', 'domain', '-', 'specific', 'summarization', 'techniques', 'that', 'utilize', 'the', 'available', 'knowledge', 'specific', 'to', 'the', 'domain', 'of', 'text', '.', 'For', 'example', ',', 'automatic', 'summarization', 'research', 'on', 'medical', 'text', 'generally', 'attempts', 'to', 'utilize', 'the', 'various', 'sources', 'of', 'codified', 'medical', 'knowledge', 'and', 'ontologies.[34', ']', '\\n\\n', 'Evaluating', 'summaries', 'qualitatively', '\\n', 'The', 'main', 'drawback', 'of', 'the', 'evaluation', 'systems', 'existing', 'so', 'far', 'is', 'that', 'we', 'need', 'at', 'least', 'one', 'reference', 'summary', ',', 'and', 'for', 'some', 'methods', 'more', 'than', 'one', ',', 'to', 'be', 'able', 'to', 'compare', 'automatic', 'summaries', 'with', 'models', '.', 'This', 'is', 'a', 'hard', 'and', 'expensive', 'task', '.', 'Much', 'effort', 'has', 'to', 'be', 'done', 'in', 'order', 'to', 'have', 'corpus', 'of', 'texts', 'and', 'their', 'corresponding', 'summaries', '.', 'Furthermore', ',', 'for', 'some', 'methods', ',', 'not', 'only', 'do', 'we', 'need', 'to', 'have', 'human', '-', 'made', 'summaries', 'available', 'for', 'comparison', ',', 'but', 'also', 'manual', 'annotation', 'has', 'to', 'be', 'performed', 'in', 'some', 'of', 'them', '(', 'e.g.', 'SCU', 'in', 'the', 'Pyramid', 'Method', ')', '.', 'In', 'any', 'case', ',', 'what', 'the', 'evaluation', 'methods', 'need', 'as', 'an', 'input', ',', 'is', 'a', 'set', 'of', 'summaries', 'to', 'serve', 'as', 'gold', 'standards', 'and', 'a', 'set', 'of', 'automatic', 'summaries', '.', 'Moreover', ',', 'they', 'all', 'perform', 'a', 'quantitative', 'evaluation', 'with', 'regard', 'to', 'different', 'similarity', 'metrics', '.', '\\n\\n', 'History', '\\n', 'The', 'first', 'publication', 'in', 'the', 'area', 'dates', 'back', 'to', '1957', '[', '35', ']', '(', 'Hans', 'Peter', 'Luhn', ')', ',', 'starting', 'with', 'a', 'statistical', 'technique', '.', 'Research', 'increased', 'significantly', 'in', '2015', '.', 'Term', 'frequency', '–', 'inverse', 'document', 'frequency', 'had', 'been', 'used', 'by', '2016', '.', 'Pattern', '-', 'based', 'summarization', 'was', 'the', 'most', 'powerful', 'option', 'for', 'multi', '-', 'document', 'summarization', 'found', 'by', '2016', '.', 'In', 'the', 'following', 'year', 'it', 'was', 'surpassed', 'by', 'latent', 'semantic', 'analysis', '(', 'LSA', ')', 'combined', 'with', 'non', '-', 'negative', 'matrix', 'factorization', '(', 'NMF', ')', '.', 'Although', 'they', 'did', 'not', 'replace', 'other', 'approaches', 'and', 'are', 'often', 'combined', 'with', 'them', ',', 'by', '2019', 'machine', 'learning', 'methods', 'dominated', 'the', 'extractive', 'summarization', 'of', 'single', 'documents', ',', 'which', 'was', 'considered', 'to', 'be', 'nearing', 'maturity', '.', 'By', '2020', ',', 'the', 'field', 'was', 'still', 'very', 'active', 'and', 'research', 'is', 'shifting', 'towards', 'abstractive', 'summation', 'and', 'real', '-', 'time', 'summarization.[36', ']', '\\n\\n', 'Recent', 'approaches', '\\n', 'Recently', 'the', 'rise', 'of', 'Transformer', 'models', 'replacing', 'more', 'traditional', 'RNN', '(', 'LSTM', ')', 'have', 'provided', 'a', 'flexibility', 'in', 'the', 'mapping', 'of', 'text', 'sequences', 'to', 'text', 'sequences', 'of', 'a', 'different', 'type', ',', 'which', 'is', 'well', 'suited', 'to', 'automatic', 'summarization', '.', 'This', 'includes', 'models', 'such', 'as', 'T5[37', ']', 'and', 'Pegasus', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **REMOVING THE STOP WORDS AND PUNCTUATIONS**"
      ],
      "metadata": {
        "id": "FIXwkOw5-XOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation =  punctuation + '\\n'\n",
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M71z2AR__U-4",
        "outputId": "6407c3d6-9124-4a89-8d27-febd993d0a31"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = {}\n",
        "for word in doc:\n",
        "    if word.text.lower() not in stopwords:\n",
        "       if word.text.lower() not in punctuation:\n",
        "         if word.text not in word_frequencies.keys():\n",
        "           word_frequencies[word.text] = 1\n",
        "         else:\n",
        "           word_frequencies[word.text] += 1"
      ],
      "metadata": {
        "id": "7VduVCmP_nQk"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fikhwUOlA-MQ",
        "outputId": "37ba9848-ecd2-4f94-bf58-01cc87d728f0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'Commercial': 1, 'products': 1, '2022': 1, 'Google': 2, 'Docs': 1, 'released': 1, 'automatic': 14, 'summarization': 82, 'feature.[6': 1, '\\n\\n': 57, 'Approaches': 2, 'general': 5, 'approaches': 7, 'extraction': 20, 'abstraction': 1, 'Extraction': 2, 'based': 25, 'content': 9, 'extracted': 5, 'original': 10, 'data': 5, 'modified': 1, 'way': 13, 'Examples': 1, 'include': 8, 'key': 5, 'phrases': 6, 'tag': 1, 'index': 2, 'text': 48, 'document': 42, 'sentences': 32, 'including': 2, 'headings': 2, 'collectively': 1, 'comprise': 1, 'abstract': 3, 'representative': 3, 'images': 5, 'video': 3, 'segments': 2, 'stated': 1, 'analogous': 1, 'process': 6, 'skimming': 1, 'summary': 32, 'available': 4, 'subheadings': 1, 'figures': 1, 'paragraphs': 1, 'section': 3, 'optionally': 1, 'paragraph': 1, 'read': 3, 'chooses': 1, 'entire': 2, 'detail.[7': 1, 'examples': 10, 'sequences': 4, 'terms': 4, 'clinical': 1, 'relevance': 5, 'patient': 1, 'problem': 11, 'intervention': 2, 'outcome).[8': 1, 'Abstraction': 3, 'applied': 6, 'mainly': 2, 'Abstractive': 1, 'methods': 15, 'build': 2, 'internal': 1, 'semantic': 4, 'representation': 3, 'use': 7, 'create': 6, 'closer': 1, 'human': 12, 'express': 1, 'transform': 1, 'paraphrasing': 1, 'sections': 1, 'source': 5, 'condense': 1, 'strongly': 1, 'transformation': 1, 'computationally': 1, 'challenging': 1, 'involving': 1, 'natural': 4, 'language': 4, 'processing': 6, 'deep': 2, 'understanding': 2, 'domain': 14, 'cases': 3, 'relates': 1, 'special': 5, 'field': 2, 'knowledge': 4, 'Paraphrasing': 1, 'difficult': 4, 'apply': 4, 'image': 5, 'systems': 13, 'extractive': 6, 'Aided': 3, 'aimed': 2, 'higher': 1, 'quality': 1, 'rely': 2, 'combined': 6, 'software': 2, 'effort': 2, 'Machine': 2, 'Human': 3, 'Summarization': 4, 'techniques': 8, 'highlight': 1, 'candidate': 1, 'passages': 1, 'inclusion': 2, 'adds': 1, 'removes': 2, 'post': 3, 'processes': 2, 'output': 4, 'edits': 1, 'translation': 4, 'Translate': 1, 'Applications': 2, 'broadly': 1, 'types': 1, 'tasks': 4, 'depending': 2, 'program': 1, 'focuses': 2, 'generic': 4, 'obtaining': 1, 'collection': 5, 'documents': 16, 'sets': 2, 'videos': 3, 'news': 12, 'stories': 1, 'etc': 6, 'second': 2, 'query': 5, 'relevant': 4, 'called': 6, 'summarizes': 4, 'objects': 3, 'specific': 7, 'able': 5, 'summaries': 24, 'machine': 7, 'generated': 5, 'user': 6, 'needs': 2, 'example': 21, 'attempts': 3, 'automatically': 6, 'produce': 11, 'given': 5, 'interested': 1, 'generating': 6, 'single': 5, 'multiple': 7, 'cluster': 3, 'articles': 7, 'topic': 5, 'multi': 11, 'related': 4, 'application': 4, 'summarizing': 4, 'Imagine': 2, 'system': 17, 'pulls': 1, 'web': 1, 'concisely': 1, 'represents': 1, 'latest': 1, 'Image': 1, 'consists': 1, 'selecting': 3, 'set': 19, 'larger': 4, 'images.[9': 1, 'context': 1, 'useful': 4, 'results': 10, 'exploration': 1, 'Video': 1, 'creates': 2, 'trailer': 1, 'long': 3, 'applications': 4, 'consumer': 1, 'personal': 1, 'want': 5, 'skip': 1, 'boring': 2, 'repetitive': 1, 'actions': 1, 'Similarly': 7, 'surveillance': 1, 'extract': 3, 'important': 10, 'suspicious': 1, 'activity': 1, 'ignoring': 1, 'redundant': 2, 'frames': 1, 'captured': 1, 'high': 5, 'level': 3, 'algorithms': 8, 'try': 2, 'find': 3, 'subsets': 1, 'like': 11, 'cover': 7, 'information': 15, 'core': 1, 'model': 10, 'notions': 2, 'diversity': 10, 'coverage': 6, 'representativeness': 1, 'Query': 1, 'additionally': 1, 'naturally': 3, 'problems': 6, 'TextRank': 17, 'PageRank': 8, 'Submodular': 6, 'function': 9, 'Determinantal': 1, 'point': 3, 'maximal': 1, 'marginal': 1, 'MMR': 1, 'Keyphrase': 3, 'task': 7, 'following': 4, 'piece': 2, 'journal': 2, 'article': 4, 'list': 2, 'keywords': 2, 'key[phrase]s': 1, 'capture': 1, 'primary': 1, 'topics': 2, 'discussed': 4, 'text.[10': 1, 'case': 10, 'research': 5, 'authors': 3, 'provide': 3, 'manually': 2, 'assigned': 2, 'lacks': 1, 'pre': 1, 'existing': 4, 'keyphrases': 30, 'rarely': 1, 'attached': 1, 'number': 10, 'Consider': 1, 'Army': 2, 'Corps': 2, 'Engineers': 2, 'rushing': 1, 'meet': 1, 'President': 2, 'Bush': 2, 'promise': 1, 'protect': 1, 'New': 2, 'Orleans': 2, 'start': 1, '2006': 1, 'hurricane': 1, 'season': 1, 'installed': 1, 'defective': 2, 'flood': 2, 'control': 2, 'pumps': 2, 'year': 2, 'despite': 1, 'warnings': 1, 'expert': 1, 'equipment': 1, 'fail': 1, 'storm': 1, 'according': 1, 'obtained': 3, 'Associated': 1, 'Press': 1, 'keyphrase': 17, 'extractor': 2, 'select': 3, 'pulled': 1, 'directly': 1, 'contrast': 1, 'abstractive': 2, 'internalize': 1, 'generate': 2, 'appear': 8, 'closely': 1, 'resemble': 1, 'political': 1, 'negligence': 1, 'inadequate': 1, 'protection': 1, 'floods': 1, 'requires': 2, 'makes': 2, 'computer': 1, 'Keyphrases': 1, 'enable': 1, 'browsing': 1, 'providing': 1, 'short': 2, 'improve': 1, 'retrieval': 2, 'search': 3, 'reliable': 1, 'hits': 1, 'employed': 1, 'entries': 1, 'large': 5, 'corpus': 3, 'Depending': 1, 'different': 9, 'literature': 1, 'definition': 1, 'words': 9, 'keyword': 1, 'highly': 6, 'theme': 1, 'Supervised': 3, 'learning': 14, 'Beginning': 1, 'work': 5, 'Turney,[11': 1, 'researchers': 2, 'approached': 1, 'supervised': 15, 'Given': 1, 'construct': 1, 'unigram': 4, 'bigram': 3, 'trigram': 3, 'found': 5, 'units': 3, 'possible': 2, 'compute': 1, 'features': 15, 'describing': 1, 'e.g.': 3, 'phrase': 3, 'begin': 1, 'upper': 1, 'letter': 1, 'assume': 1, 'known': 10, 'training': 12, 'assign': 3, 'positive': 2, 'negative': 3, 'labels': 2, 'learn': 7, 'classifier': 5, 'discriminate': 2, 'classifiers': 2, 'binary': 3, 'classification': 7, 'test': 4, 'probability': 2, 'instance': 3, 'rule': 2, 'says': 1, 'initial': 1, 'capital': 1, 'letters': 1, 'likely': 5, 'learner': 2, 'manner': 2, 'generation': 1, 'strategy': 1, 'run': 2, 'determine': 4, 'looking': 1, 'decisions': 1, 'probabilities': 4, 'returned': 1, 'learned': 1, 'threshold': 4, 'extractors': 1, 'generally': 3, 'evaluated': 2, 'precision': 2, 'recall': 4, 'Precision': 1, 'measures': 4, 'proposed': 3, 'actually': 1, 'correct': 1, 'Recall': 5, 'true': 1, 'F': 2, 'score': 4, 'harmonic': 1, 'mean': 2, '2PR/(P': 1, 'R': 1, 'Matches': 1, 'checked': 1, 'stemming': 1, 'applying': 4, 'normalization': 1, 'Designing': 1, 'involves': 2, 'deciding': 1, 'choices': 1, 'unsupervised': 5, 'choice': 1, 'exactly': 2, 'Turney': 6, 'unigrams': 13, 'bigrams': 2, 'trigrams': 2, 'intervening': 1, 'punctuation': 1, 'removing': 1, 'stopwords': 1, 'Hulth': 3, 'showed': 1, 'improvement': 1, 'tokens': 1, 'match': 2, 'certain': 1, 'patterns': 1, 'speech': 2, 'tags': 1, 'Ideally': 2, 'mechanism': 1, 'produces': 1, 'labeled': 2, 'candidates': 2, 'containing': 1, 'suffer': 1, 'lead': 1, 'low': 1, 'need': 11, 'describe': 1, 'informative': 1, 'allow': 1, 'algorithm': 15, 'non-': 1, 'Typically': 1, 'involve': 1, 'term': 1, 'frequencies': 1, 'times': 2, 'appears': 3, 'current': 1, 'length': 5, 'relative': 1, 'position': 5, 'occurrence': 4, 'boolean': 1, 'syntactic': 1, 'contains': 2, 'caps': 1, 'paper': 3, '12': 1, 'uses': 4, 'reduced': 1, 'successful': 1, 'KEA': 1, 'Algorithm': 1, 'derived': 1, 'seminal': 1, 'end': 3, 'return': 1, 'limit': 2, 'Ensemble': 1, 'i.e.': 5, 'votes': 1, 'numeric': 1, 'scores': 3, 'thresholded': 1, 'provided': 2, 'technique': 3, 'C4.5': 1, 'decision': 2, 'trees': 2, 'implicitly': 1, 'determines': 2, 'appropriate': 1, 'created': 4, 'predict': 1, 'Virtually': 1, 'Naive': 1, 'Bayes': 2, 'induction': 1, 'GenEx': 1, 'genetic': 2, 'parameters': 3, 'follows': 1, 'series': 1, 'heuristics': 2, 'identify': 3, 'optimizes': 1, 'respect': 2, 'performance': 2, 'Unsupervised': 2, 'approach': 5, 'nice': 2, 'properties': 2, 'interpretable': 1, 'rules': 1, 'characterize': 2, 'require': 1, 'needed': 3, 'Furthermore': 2, 'tends': 1, 'customize': 1, 'resulting': 3, 'necessarily': 2, 'portable': 3, 'demonstrate': 1, 'angle': 1, 'Instead': 1, 'trying': 2, 'explicit': 1, 'algorithm[12': 1, 'exploits': 1, 'structure': 1, 'central': 3, 'selects': 1, 'Web': 2, 'pages': 2, 'notion': 2, 'prestige': 1, 'recommendation': 1, 'social': 1, 'networks': 1, 'previous': 1, 'arbitrary': 3, 'simply': 4, 'intrinsic': 3, 'easily': 3, 'new': 3, 'domains': 1, 'languages': 1, 'purpose': 2, 'graph': 15, 'ranking': 7, 'NLP': 4, 'Essentially': 1, 'runs': 1, 'specially': 1, 'designed': 1, 'particular': 2, 'builds': 2, 'vertices': 8, 'Edges': 2, 'measure': 5, 'lexical': 1, 'similarity': 9, 'unit': 1, 'Unlike': 1, 'edges': 5, 'typically': 4, 'undirected': 1, 'weighted': 1, 'reflect': 1, 'degree': 2, 'constructed': 2, 'form': 3, 'stochastic': 1, 'matrix': 2, 'damping': 1, 'factor': 2, 'random': 7, 'surfer': 1, 'finding': 2, 'eigenvector': 2, 'corresponding': 2, 'eigenvalue': 1, '1': 1, 'stationary': 4, 'distribution': 2, 'walk': 5, 'correspond': 1, 'rank': 6, 'Potentially': 1, 'similar': 12, 'vertex': 3, 'small': 1, 'decide': 1, 'individual': 3, 'step': 7, 'merges': 1, 'ranked': 5, 'adjacent': 2, 'word': 5, 'effect': 1, 'allowing': 1, 'advanced': 1, 'ranks': 2, 'look': 1, 'consecutively': 1, 'final': 4, 'Note': 4, 'placed': 3, 'filtered': 1, 'adjectives': 1, 'nouns': 1, 'best': 2, 'linguistic': 1, 'comes': 1, 'play': 1, 'co': 5, 'connected': 3, 'edge': 2, 'window': 1, 'size': 2, 'N': 3, '2–10': 1, 'linked': 2, 'Natural': 1, 'string': 1, 'cohesion': 1, 'idea': 4, 'near': 1, 'meaningful': 1, 'recommend': 2, 'reader': 2, 'method': 3, 'limited': 1, 'chosen': 1, 'count': 3, 'T': 5, 'specified': 2, 'fraction': 1, 'total': 1, 'selected': 2, 'post-': 1, 'merge': 1, 'instances': 3, 'result': 3, 'potentially': 1, 'produced': 1, 'roughly': 1, 'proportional': 1, 'initially': 1, 'clear': 1, 'think': 1, 'occurring': 1, 'neighbors': 2, 'occur': 2, 'un': 1, 'semi': 1, 'hub': 1, 'connects': 1, 'modifying': 1, 'Running': 1, 'places': 1, 'importance': 6, 'contribute': 1, 'ends': 1, 'probably': 2, 'contain': 3, 'densely': 2, 'regions': 1, 'contexts': 1, 'assigns': 1, 'centers': 1, 'clusters': 1, 'getting': 2, 'considered': 4, 'Document': 3, 'Like': 1, 'aims': 1, 'essence': 1, 'real': 2, 'difference': 1, 'dealing': 1, '—': 2, 'instead': 1, 'details': 1, 'mention': 1, 'common': 3, 'ROUGE': 6, 'Oriented': 2, 'Understudy': 2, 'Gisting': 2, 'Evaluation': 4, 'covers': 1, 'present': 2, 'references': 2, 'encourage': 1, 'computed': 2, '4-gram': 1, 'matching': 1, 'ROUGE-1': 3, 'division': 1, 'reference': 5, 'averaged': 1, 'overlap': 4, 'concepts': 4, 'coherent': 1, 'flow': 1, 'sensible': 1, 'High': 1, 'order': 3, 'n': 2, 'gram': 2, 'judge': 1, 'fluency': 1, 'BLEU': 2, 'precision-': 1, 'favor': 1, 'accuracy': 1, 'promising': 1, 'line': 1, 'adaptive': 3, 'summarization.[13': 1, 'preliminary': 1, 'recognition': 1, 'genre': 2, 'subsequent': 1, 'optimized': 1, 'perform': 2, 'created.[14': 1, 'Basically': 1, 'good': 3, 'Features': 1, 'sentence': 14, 'main': 3, 'difficulty': 1, 'extracting': 1, 'people': 1, 'abstracts': 1, 'usually': 1, 'sufficient': 1, 'evaluation': 10, 'purposes': 1, 'cares': 1, 'Maximum': 3, 'entropy': 3, 'DUC': 2, '2001': 1, '2002': 1, 'workshops': 1, 'TNO': 1, 'developed': 4, 'hybrid': 1, 'naive': 1, 'statistical': 2, 'models': 9, 'modeling': 2, 'salience': 1, 'exhibited': 1, 'wanted': 1, 'explore': 1, 'effectiveness': 1, 'maximum': 1, 'meeting': 1, 'robust': 1, 'feature': 1, 'dependencies': 1, 'successfully': 2, 'broadcast': 1, 'LexRank': 10, 'spirit': 1, 'gets': 1, 'issue': 2, 'costly': 1, 'centroid': 2, 'vector': 1, 'regard': 2, 'principled': 1, 'estimate': 1, 'walks': 2, 'centrality': 2, 'LexRank[15': 1, 'essentially': 2, 'identical': 1, 'groups': 2, 'time': 4, 'focused': 1, 'creating': 1, 'cosine': 2, 'TF': 1, 'IDF': 1, 'vectors': 1, 'normalized': 1, 'lengths': 1, 'explored': 1, 'unweighted': 1, 'values': 1, 'experimented': 1, 'weights': 3, 'equal': 1, 'continuous': 1, 'formed': 1, 'combining': 1, 'cutoff': 1, 'worth': 1, 'noting': 1, 'described': 2, 'MEAD': 1, 'combines': 1, 'linear': 1, 'combination': 1, 'tuned': 1, 'additional': 1, 'absolutely': 1, 'necessary': 1, 'distinction': 1, 'remains': 2, 'choose': 1, 'grown': 1, 'greater': 1, 'risk': 1, 'duplicate': 1, 'place': 1, 'event': 1, 'distinct': 1, 'ideas': 2, 'address': 1, 'applies': 2, 'heuristic': 2, 'adding': 2, 'discards': 1, 'ones': 2, 'Cross': 1, 'Sentence': 1, 'Information': 1, 'Subsumption': 1, 'CSIS': 2, 'great': 1, 'stems': 1, 'recommending': 1, 'turn': 1, 'intuitive': 1, 'sense': 1, 'allows': 2, 'independent': 3, 'imagine': 1, 'indicating': 1, 'vary': 1, 'considerably': 1, 'biomedical': 1, 'recommendation\"-based': 1, 'Multi': 6, 'Main': 1, 'procedure': 2, 'texts': 2, 'written': 2, 'Resulting': 1, 'report': 1, 'users': 1, 'professional': 1, 'consumers': 1, 'quickly': 1, 'familiarize': 1, 'contained': 1, 'complementing': 1, 'aggregators': 1, 'performing': 1, 'road': 1, 'coping': 1, 'overload': 1, 'response': 1, 'question.[16][8': 1, 'reports': 1, 'concise': 1, 'comprehensive': 2, 'opinions': 1, 'outlined': 1, 'perspectives': 1, 'goal': 1, 'brief': 1, 'simplify': 1, 'cut': 1, 'pointing': 1, 'required': 2, 'limiting': 1, 'accessing': 1, 'files': 1, 'refinement': 1, 'Automatic': 1, 'sources': 2, 'algorithmically': 1, 'editorial': 1, 'touch': 1, 'subjective': 1, 'making': 2, 'completely': 1, 'unbiased.[dubious': 1, '–': 2, 'discuss': 1, 'Incorporating': 1, 'faces': 1, 'potential': 1, 'redundancy': 3, 'diverse': 1, 'differ': 1, 'deals': 1, 'stage': 1, 'Maximal': 1, 'Marginal': 2, 'Relevance': 2, 'MMR),[17': 1, 'eliminate': 1, 'Page': 1, 'Lex': 1, 'handles': 1, 'unified': 1, 'mathematical': 1, 'framework': 1, 'absorbing': 3, 'Markov': 1, 'chain': 1, 'standard': 1, 'states': 2, 'act': 1, 'black': 1, 'holes': 1, 'cause': 1, 'abruptly': 1, 'state': 5, 'GRASSHOPPER.[18': 1, 'addition': 1, 'explicitly': 1, 'promoting': 1, 'GRASSHOPPER': 1, 'incorporates': 1, 'prior': 1, 'art': 4, 'mixtures': 2, 'submodular': 20, 'functions': 13, 'achieved': 3, 'Corpora': 1, '04': 1, '07.[19': 1, 'Similar': 1, 'determinantal': 2, 'DUC-04.[20': 1, 'lingual': 1, 'avoids': 1, 'works': 2, 'simplifying': 1, 'ideograms': 3, 'represent': 2, 'meaning': 2, 'evaluates': 1, 'qualitatively': 2, 'comparing': 1, 'shape': 1, 'said': 1, 'recently': 2, 'tool': 2, 'frequency': 3, 'preprocessing': 1, 'kind': 1, 'supplied': 1, 'equivalence': 1, 'equivalent': 1, 'desired': 1, 'tools': 1, 'emerged': 1, 'powerful': 2, 'combinatorial': 1, 'optimization': 6, 'subset': 1, 'facility': 1, 'location': 1, 'Facility': 1, 'Location': 1, 'seen': 1, 'encouraging': 1, 'efficiently': 1, 'combine': 1, 'supervision': 1, 'right': 2, 'fitting': 1, 'admit': 1, 'efficient': 1, 'simple': 2, 'greedy': 2, 'admits': 1, 'constant': 1, 'guarantee.[21': 1, 'extremely': 1, 'implement': 1, 'scale': 1, 'datasets': 1, 'Lin': 2, 'Bilmes': 2, '2012[22': 1, 'shows': 2, 'achieve': 2, 'date': 1, 'DUC-04': 1, 'DUC-05': 1, 'DUC-06': 1, 'DUC-07': 1, '2011,[23': 1, 'breakthrough': 1, 'establishing': 1, 'problems.[citation': 1, 'Functions': 2, 'Tschiatschek': 2, 'et': 3, 'al': 3, '2014': 1, 'show[24': 1, 'Bairi': 1, '2015[25': 1, 'utility': 1, 'hierarchies': 1, 'datasets.[26': 1, 'icon': 1, '\\t\\n': 1, 'expansion': 1, 'help': 1, 'February': 1, '2017': 1, 'Specific': 1, 'Reddit': 1, 'bot': 1, 'autotldr\",[27': 1, '2011': 1, 'comment': 1, 'reddit': 2, 'posts': 1, 'community': 1, 'upvoted': 1, 'hundreds': 1, 'thousands': 1, 'times.[28': 1, 'TL;DR': 1, '−': 1, 'Internet': 1, 'slang': 1, 'read\".[29][30': 1, 'evaluate': 1, 'informativeness': 2, 'compare': 2, 'fall': 1, 'extrinsic,[31': 1, 'inter': 2, 'textual': 5, 'intra': 2, 'textual.[32': 1, 'Intrinsic': 2, 'extrinsic': 2, 'tests': 2, 'affects': 1, 'completion': 1, 'evaluations': 2, 'assessed': 1, 'coherence': 3, 'Extrinsic': 1, 'hand': 1, 'tested': 1, 'impact': 1, 'assessment': 1, 'reading': 1, 'comprehension': 1, 'Inter': 1, 'Intra': 1, 'assess': 1, 'focus': 2, 'contrastive': 1, 'analysis': 2, 'outputs': 1, 'judgement': 1, 'wide': 1, 'variance': 1, 'means': 1, 'particularly': 1, 'Manual': 1, 'labor': 1, 'intensive': 1, 'humans': 1, 'issues': 1, 'concerning': 1, 'metrics': 3, 'NIST': 1, 'annual': 1, 'Understanding': 1, 'Conferences': 1, 'submit': 1, 'metric': 1, '2': 1, 'calculates': 1, 'overlaps': 1, 'previously': 1, 'indicate': 1, 'shared': 1, 'unable': 1, 'feedback': 1, 'Anaphor': 1, 'resolution': 1, 'fully': 1, 'solved': 1, 'Visual': 1, 'judges': 1, 'summarization.[33': 1, 'Domain': 2, 'versus': 1, 'rich': 1, 'Recent': 2, 'drifted': 1, 'utilize': 2, 'medical': 2, 'codified': 1, 'ontologies.[34': 1, 'Evaluating': 1, 'drawback': 1, 'far': 1, 'hard': 1, 'expensive': 1, 'comparison': 1, 'manual': 1, 'annotation': 1, 'performed': 1, 'SCU': 1, 'Pyramid': 1, 'Method': 1, 'input': 1, 'serve': 1, 'gold': 1, 'standards': 1, 'quantitative': 1, 'History': 1, 'publication': 1, 'area': 1, 'dates': 1, '1957': 1, '35': 1, 'Hans': 1, 'Peter': 1, 'Luhn': 1, 'starting': 1, 'Research': 1, 'increased': 1, 'significantly': 1, '2015': 1, 'Term': 1, 'inverse': 1, '2016': 2, 'Pattern': 1, 'option': 1, 'surpassed': 1, 'latent': 1, 'LSA': 1, 'non': 1, 'factorization': 1, 'NMF': 1, 'replace': 1, '2019': 1, 'dominated': 1, 'nearing': 1, 'maturity': 1, '2020': 1, 'active': 1, 'shifting': 1, 'summation': 1, 'summarization.[36': 1, 'Recently': 1, 'rise': 1, 'Transformer': 1, 'replacing': 1, 'traditional': 1, 'RNN': 1, 'LSTM': 1, 'flexibility': 1, 'mapping': 1, 'type': 1, 'suited': 1, 'includes': 1, 'T5[37': 1, 'Pegasus': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(res.keys())\n",
        "values = list(res.values())"
      ],
      "metadata": {
        "id": "b7QciwEfBsH1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Xsak7aR-CxVU"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "BUQh2wpXEbbx"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.title('Most Occuring Words')\n",
        "plt.barh(range(len(res)), values, tick_label=words)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "K0XFa6UzCZNa",
        "outputId": "dce4106b-8c69-4755-b592-fb4f59ed6a2d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize N \n",
        "N = 25"
      ],
      "metadata": {
        "id": "UOu6Uj3-CwRJ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict = word_frequencies"
      ],
      "metadata": {
        "id": "RJmTIuxoEOSG"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = dict(sorted(test_dict.items(), key = itemgetter(1), reverse = True)[:N])"
      ],
      "metadata": {
        "id": "HX22cyKuFOfp"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhLM_0KnFQlf",
        "outputId": "87117022-a34c-4a56-f643-fa345d17ecd3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n\\n': 57,\n",
              " 'TextRank': 17,\n",
              " 'algorithm': 15,\n",
              " 'automatic': 14,\n",
              " 'based': 25,\n",
              " 'document': 42,\n",
              " 'documents': 16,\n",
              " 'domain': 14,\n",
              " 'example': 21,\n",
              " 'extraction': 20,\n",
              " 'features': 15,\n",
              " 'graph': 15,\n",
              " 'information': 15,\n",
              " 'keyphrase': 17,\n",
              " 'keyphrases': 30,\n",
              " 'methods': 15,\n",
              " 'sentences': 32,\n",
              " 'set': 19,\n",
              " 'submodular': 20,\n",
              " 'summaries': 24,\n",
              " 'summarization': 82,\n",
              " 'summary': 32,\n",
              " 'supervised': 15,\n",
              " 'system': 17,\n",
              " 'text': 48}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency = max(word_frequencies.values())\n",
        "max_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9AhqEQsFA5_",
        "outputId": "1739dbb9-2166-456f-c073-4eff7ce4f36a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NORMALIZING WORD FREQUENCY**"
      ],
      "metadata": {
        "id": "XvBZ1n2qWQkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word]/max_frequency"
      ],
      "metadata": {
        "id": "CZNBL6kCGcud"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ebMUr8SW6Yt",
        "outputId": "32895c66-f07c-44da-e48c-4131eff10178"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0.012195121951219513, 'Commercial': 0.012195121951219513, 'products': 0.012195121951219513, '2022': 0.012195121951219513, 'Google': 0.024390243902439025, 'Docs': 0.012195121951219513, 'released': 0.012195121951219513, 'automatic': 0.17073170731707318, 'summarization': 1.0, 'feature.[6': 0.012195121951219513, '\\n\\n': 0.6951219512195121, 'Approaches': 0.024390243902439025, 'general': 0.06097560975609756, 'approaches': 0.08536585365853659, 'extraction': 0.24390243902439024, 'abstraction': 0.012195121951219513, 'Extraction': 0.024390243902439025, 'based': 0.3048780487804878, 'content': 0.10975609756097561, 'extracted': 0.06097560975609756, 'original': 0.12195121951219512, 'data': 0.06097560975609756, 'modified': 0.012195121951219513, 'way': 0.15853658536585366, 'Examples': 0.012195121951219513, 'include': 0.0975609756097561, 'key': 0.06097560975609756, 'phrases': 0.07317073170731707, 'tag': 0.012195121951219513, 'index': 0.024390243902439025, 'text': 0.5853658536585366, 'document': 0.5121951219512195, 'sentences': 0.3902439024390244, 'including': 0.024390243902439025, 'headings': 0.024390243902439025, 'collectively': 0.012195121951219513, 'comprise': 0.012195121951219513, 'abstract': 0.036585365853658534, 'representative': 0.036585365853658534, 'images': 0.06097560975609756, 'video': 0.036585365853658534, 'segments': 0.024390243902439025, 'stated': 0.012195121951219513, 'analogous': 0.012195121951219513, 'process': 0.07317073170731707, 'skimming': 0.012195121951219513, 'summary': 0.3902439024390244, 'available': 0.04878048780487805, 'subheadings': 0.012195121951219513, 'figures': 0.012195121951219513, 'paragraphs': 0.012195121951219513, 'section': 0.036585365853658534, 'optionally': 0.012195121951219513, 'paragraph': 0.012195121951219513, 'read': 0.036585365853658534, 'chooses': 0.012195121951219513, 'entire': 0.024390243902439025, 'detail.[7': 0.012195121951219513, 'examples': 0.12195121951219512, 'sequences': 0.04878048780487805, 'terms': 0.04878048780487805, 'clinical': 0.012195121951219513, 'relevance': 0.06097560975609756, 'patient': 0.012195121951219513, 'problem': 0.13414634146341464, 'intervention': 0.024390243902439025, 'outcome).[8': 0.012195121951219513, 'Abstraction': 0.036585365853658534, 'applied': 0.07317073170731707, 'mainly': 0.024390243902439025, 'Abstractive': 0.012195121951219513, 'methods': 0.18292682926829268, 'build': 0.024390243902439025, 'internal': 0.012195121951219513, 'semantic': 0.04878048780487805, 'representation': 0.036585365853658534, 'use': 0.08536585365853659, 'create': 0.07317073170731707, 'closer': 0.012195121951219513, 'human': 0.14634146341463414, 'express': 0.012195121951219513, 'transform': 0.012195121951219513, 'paraphrasing': 0.012195121951219513, 'sections': 0.012195121951219513, 'source': 0.06097560975609756, 'condense': 0.012195121951219513, 'strongly': 0.012195121951219513, 'transformation': 0.012195121951219513, 'computationally': 0.012195121951219513, 'challenging': 0.012195121951219513, 'involving': 0.012195121951219513, 'natural': 0.04878048780487805, 'language': 0.04878048780487805, 'processing': 0.07317073170731707, 'deep': 0.024390243902439025, 'understanding': 0.024390243902439025, 'domain': 0.17073170731707318, 'cases': 0.036585365853658534, 'relates': 0.012195121951219513, 'special': 0.06097560975609756, 'field': 0.024390243902439025, 'knowledge': 0.04878048780487805, 'Paraphrasing': 0.012195121951219513, 'difficult': 0.04878048780487805, 'apply': 0.04878048780487805, 'image': 0.06097560975609756, 'systems': 0.15853658536585366, 'extractive': 0.07317073170731707, 'Aided': 0.036585365853658534, 'aimed': 0.024390243902439025, 'higher': 0.012195121951219513, 'quality': 0.012195121951219513, 'rely': 0.024390243902439025, 'combined': 0.07317073170731707, 'software': 0.024390243902439025, 'effort': 0.024390243902439025, 'Machine': 0.024390243902439025, 'Human': 0.036585365853658534, 'Summarization': 0.04878048780487805, 'techniques': 0.0975609756097561, 'highlight': 0.012195121951219513, 'candidate': 0.012195121951219513, 'passages': 0.012195121951219513, 'inclusion': 0.024390243902439025, 'adds': 0.012195121951219513, 'removes': 0.024390243902439025, 'post': 0.036585365853658534, 'processes': 0.024390243902439025, 'output': 0.04878048780487805, 'edits': 0.012195121951219513, 'translation': 0.04878048780487805, 'Translate': 0.012195121951219513, 'Applications': 0.024390243902439025, 'broadly': 0.012195121951219513, 'types': 0.012195121951219513, 'tasks': 0.04878048780487805, 'depending': 0.024390243902439025, 'program': 0.012195121951219513, 'focuses': 0.024390243902439025, 'generic': 0.04878048780487805, 'obtaining': 0.012195121951219513, 'collection': 0.06097560975609756, 'documents': 0.1951219512195122, 'sets': 0.024390243902439025, 'videos': 0.036585365853658534, 'news': 0.14634146341463414, 'stories': 0.012195121951219513, 'etc': 0.07317073170731707, 'second': 0.024390243902439025, 'query': 0.06097560975609756, 'relevant': 0.04878048780487805, 'called': 0.07317073170731707, 'summarizes': 0.04878048780487805, 'objects': 0.036585365853658534, 'specific': 0.08536585365853659, 'able': 0.06097560975609756, 'summaries': 0.2926829268292683, 'machine': 0.08536585365853659, 'generated': 0.06097560975609756, 'user': 0.07317073170731707, 'needs': 0.024390243902439025, 'example': 0.25609756097560976, 'attempts': 0.036585365853658534, 'automatically': 0.07317073170731707, 'produce': 0.13414634146341464, 'given': 0.06097560975609756, 'interested': 0.012195121951219513, 'generating': 0.07317073170731707, 'single': 0.06097560975609756, 'multiple': 0.08536585365853659, 'cluster': 0.036585365853658534, 'articles': 0.08536585365853659, 'topic': 0.06097560975609756, 'multi': 0.13414634146341464, 'related': 0.04878048780487805, 'application': 0.04878048780487805, 'summarizing': 0.04878048780487805, 'Imagine': 0.024390243902439025, 'system': 0.2073170731707317, 'pulls': 0.012195121951219513, 'web': 0.012195121951219513, 'concisely': 0.012195121951219513, 'represents': 0.012195121951219513, 'latest': 0.012195121951219513, 'Image': 0.012195121951219513, 'consists': 0.012195121951219513, 'selecting': 0.036585365853658534, 'set': 0.23170731707317074, 'larger': 0.04878048780487805, 'images.[9': 0.012195121951219513, 'context': 0.012195121951219513, 'useful': 0.04878048780487805, 'results': 0.12195121951219512, 'exploration': 0.012195121951219513, 'Video': 0.012195121951219513, 'creates': 0.024390243902439025, 'trailer': 0.012195121951219513, 'long': 0.036585365853658534, 'applications': 0.04878048780487805, 'consumer': 0.012195121951219513, 'personal': 0.012195121951219513, 'want': 0.06097560975609756, 'skip': 0.012195121951219513, 'boring': 0.024390243902439025, 'repetitive': 0.012195121951219513, 'actions': 0.012195121951219513, 'Similarly': 0.08536585365853659, 'surveillance': 0.012195121951219513, 'extract': 0.036585365853658534, 'important': 0.12195121951219512, 'suspicious': 0.012195121951219513, 'activity': 0.012195121951219513, 'ignoring': 0.012195121951219513, 'redundant': 0.024390243902439025, 'frames': 0.012195121951219513, 'captured': 0.012195121951219513, 'high': 0.06097560975609756, 'level': 0.036585365853658534, 'algorithms': 0.0975609756097561, 'try': 0.024390243902439025, 'find': 0.036585365853658534, 'subsets': 0.012195121951219513, 'like': 0.13414634146341464, 'cover': 0.08536585365853659, 'information': 0.18292682926829268, 'core': 0.012195121951219513, 'model': 0.12195121951219512, 'notions': 0.024390243902439025, 'diversity': 0.12195121951219512, 'coverage': 0.07317073170731707, 'representativeness': 0.012195121951219513, 'Query': 0.012195121951219513, 'additionally': 0.012195121951219513, 'naturally': 0.036585365853658534, 'problems': 0.07317073170731707, 'TextRank': 0.2073170731707317, 'PageRank': 0.0975609756097561, 'Submodular': 0.07317073170731707, 'function': 0.10975609756097561, 'Determinantal': 0.012195121951219513, 'point': 0.036585365853658534, 'maximal': 0.012195121951219513, 'marginal': 0.012195121951219513, 'MMR': 0.012195121951219513, 'Keyphrase': 0.036585365853658534, 'task': 0.08536585365853659, 'following': 0.04878048780487805, 'piece': 0.024390243902439025, 'journal': 0.024390243902439025, 'article': 0.04878048780487805, 'list': 0.024390243902439025, 'keywords': 0.024390243902439025, 'key[phrase]s': 0.012195121951219513, 'capture': 0.012195121951219513, 'primary': 0.012195121951219513, 'topics': 0.024390243902439025, 'discussed': 0.04878048780487805, 'text.[10': 0.012195121951219513, 'case': 0.12195121951219512, 'research': 0.06097560975609756, 'authors': 0.036585365853658534, 'provide': 0.036585365853658534, 'manually': 0.024390243902439025, 'assigned': 0.024390243902439025, 'lacks': 0.012195121951219513, 'pre': 0.012195121951219513, 'existing': 0.04878048780487805, 'keyphrases': 0.36585365853658536, 'rarely': 0.012195121951219513, 'attached': 0.012195121951219513, 'number': 0.12195121951219512, 'Consider': 0.012195121951219513, 'Army': 0.024390243902439025, 'Corps': 0.024390243902439025, 'Engineers': 0.024390243902439025, 'rushing': 0.012195121951219513, 'meet': 0.012195121951219513, 'President': 0.024390243902439025, 'Bush': 0.024390243902439025, 'promise': 0.012195121951219513, 'protect': 0.012195121951219513, 'New': 0.024390243902439025, 'Orleans': 0.024390243902439025, 'start': 0.012195121951219513, '2006': 0.012195121951219513, 'hurricane': 0.012195121951219513, 'season': 0.012195121951219513, 'installed': 0.012195121951219513, 'defective': 0.024390243902439025, 'flood': 0.024390243902439025, 'control': 0.024390243902439025, 'pumps': 0.024390243902439025, 'year': 0.024390243902439025, 'despite': 0.012195121951219513, 'warnings': 0.012195121951219513, 'expert': 0.012195121951219513, 'equipment': 0.012195121951219513, 'fail': 0.012195121951219513, 'storm': 0.012195121951219513, 'according': 0.012195121951219513, 'obtained': 0.036585365853658534, 'Associated': 0.012195121951219513, 'Press': 0.012195121951219513, 'keyphrase': 0.2073170731707317, 'extractor': 0.024390243902439025, 'select': 0.036585365853658534, 'pulled': 0.012195121951219513, 'directly': 0.012195121951219513, 'contrast': 0.012195121951219513, 'abstractive': 0.024390243902439025, 'internalize': 0.012195121951219513, 'generate': 0.024390243902439025, 'appear': 0.0975609756097561, 'closely': 0.012195121951219513, 'resemble': 0.012195121951219513, 'political': 0.012195121951219513, 'negligence': 0.012195121951219513, 'inadequate': 0.012195121951219513, 'protection': 0.012195121951219513, 'floods': 0.012195121951219513, 'requires': 0.024390243902439025, 'makes': 0.024390243902439025, 'computer': 0.012195121951219513, 'Keyphrases': 0.012195121951219513, 'enable': 0.012195121951219513, 'browsing': 0.012195121951219513, 'providing': 0.012195121951219513, 'short': 0.024390243902439025, 'improve': 0.012195121951219513, 'retrieval': 0.024390243902439025, 'search': 0.036585365853658534, 'reliable': 0.012195121951219513, 'hits': 0.012195121951219513, 'employed': 0.012195121951219513, 'entries': 0.012195121951219513, 'large': 0.06097560975609756, 'corpus': 0.036585365853658534, 'Depending': 0.012195121951219513, 'different': 0.10975609756097561, 'literature': 0.012195121951219513, 'definition': 0.012195121951219513, 'words': 0.10975609756097561, 'keyword': 0.012195121951219513, 'highly': 0.07317073170731707, 'theme': 0.012195121951219513, 'Supervised': 0.036585365853658534, 'learning': 0.17073170731707318, 'Beginning': 0.012195121951219513, 'work': 0.06097560975609756, 'Turney,[11': 0.012195121951219513, 'researchers': 0.024390243902439025, 'approached': 0.012195121951219513, 'supervised': 0.18292682926829268, 'Given': 0.012195121951219513, 'construct': 0.012195121951219513, 'unigram': 0.04878048780487805, 'bigram': 0.036585365853658534, 'trigram': 0.036585365853658534, 'found': 0.06097560975609756, 'units': 0.036585365853658534, 'possible': 0.024390243902439025, 'compute': 0.012195121951219513, 'features': 0.18292682926829268, 'describing': 0.012195121951219513, 'e.g.': 0.036585365853658534, 'phrase': 0.036585365853658534, 'begin': 0.012195121951219513, 'upper': 0.012195121951219513, 'letter': 0.012195121951219513, 'assume': 0.012195121951219513, 'known': 0.12195121951219512, 'training': 0.14634146341463414, 'assign': 0.036585365853658534, 'positive': 0.024390243902439025, 'negative': 0.036585365853658534, 'labels': 0.024390243902439025, 'learn': 0.08536585365853659, 'classifier': 0.06097560975609756, 'discriminate': 0.024390243902439025, 'classifiers': 0.024390243902439025, 'binary': 0.036585365853658534, 'classification': 0.08536585365853659, 'test': 0.04878048780487805, 'probability': 0.024390243902439025, 'instance': 0.036585365853658534, 'rule': 0.024390243902439025, 'says': 0.012195121951219513, 'initial': 0.012195121951219513, 'capital': 0.012195121951219513, 'letters': 0.012195121951219513, 'likely': 0.06097560975609756, 'learner': 0.024390243902439025, 'manner': 0.024390243902439025, 'generation': 0.012195121951219513, 'strategy': 0.012195121951219513, 'run': 0.024390243902439025, 'determine': 0.04878048780487805, 'looking': 0.012195121951219513, 'decisions': 0.012195121951219513, 'probabilities': 0.04878048780487805, 'returned': 0.012195121951219513, 'learned': 0.012195121951219513, 'threshold': 0.04878048780487805, 'extractors': 0.012195121951219513, 'generally': 0.036585365853658534, 'evaluated': 0.024390243902439025, 'precision': 0.024390243902439025, 'recall': 0.04878048780487805, 'Precision': 0.012195121951219513, 'measures': 0.04878048780487805, 'proposed': 0.036585365853658534, 'actually': 0.012195121951219513, 'correct': 0.012195121951219513, 'Recall': 0.06097560975609756, 'true': 0.012195121951219513, 'F': 0.024390243902439025, 'score': 0.04878048780487805, 'harmonic': 0.012195121951219513, 'mean': 0.024390243902439025, '2PR/(P': 0.012195121951219513, 'R': 0.012195121951219513, 'Matches': 0.012195121951219513, 'checked': 0.012195121951219513, 'stemming': 0.012195121951219513, 'applying': 0.04878048780487805, 'normalization': 0.012195121951219513, 'Designing': 0.012195121951219513, 'involves': 0.024390243902439025, 'deciding': 0.012195121951219513, 'choices': 0.012195121951219513, 'unsupervised': 0.06097560975609756, 'choice': 0.012195121951219513, 'exactly': 0.024390243902439025, 'Turney': 0.07317073170731707, 'unigrams': 0.15853658536585366, 'bigrams': 0.024390243902439025, 'trigrams': 0.024390243902439025, 'intervening': 0.012195121951219513, 'punctuation': 0.012195121951219513, 'removing': 0.012195121951219513, 'stopwords': 0.012195121951219513, 'Hulth': 0.036585365853658534, 'showed': 0.012195121951219513, 'improvement': 0.012195121951219513, 'tokens': 0.012195121951219513, 'match': 0.024390243902439025, 'certain': 0.012195121951219513, 'patterns': 0.012195121951219513, 'speech': 0.024390243902439025, 'tags': 0.012195121951219513, 'Ideally': 0.024390243902439025, 'mechanism': 0.012195121951219513, 'produces': 0.012195121951219513, 'labeled': 0.024390243902439025, 'candidates': 0.024390243902439025, 'containing': 0.012195121951219513, 'suffer': 0.012195121951219513, 'lead': 0.012195121951219513, 'low': 0.012195121951219513, 'need': 0.13414634146341464, 'describe': 0.012195121951219513, 'informative': 0.012195121951219513, 'allow': 0.012195121951219513, 'algorithm': 0.18292682926829268, 'non-': 0.012195121951219513, 'Typically': 0.012195121951219513, 'involve': 0.012195121951219513, 'term': 0.012195121951219513, 'frequencies': 0.012195121951219513, 'times': 0.024390243902439025, 'appears': 0.036585365853658534, 'current': 0.012195121951219513, 'length': 0.06097560975609756, 'relative': 0.012195121951219513, 'position': 0.06097560975609756, 'occurrence': 0.04878048780487805, 'boolean': 0.012195121951219513, 'syntactic': 0.012195121951219513, 'contains': 0.024390243902439025, 'caps': 0.012195121951219513, 'paper': 0.036585365853658534, '12': 0.012195121951219513, 'uses': 0.04878048780487805, 'reduced': 0.012195121951219513, 'successful': 0.012195121951219513, 'KEA': 0.012195121951219513, 'Algorithm': 0.012195121951219513, 'derived': 0.012195121951219513, 'seminal': 0.012195121951219513, 'end': 0.036585365853658534, 'return': 0.012195121951219513, 'limit': 0.024390243902439025, 'Ensemble': 0.012195121951219513, 'i.e.': 0.06097560975609756, 'votes': 0.012195121951219513, 'numeric': 0.012195121951219513, 'scores': 0.036585365853658534, 'thresholded': 0.012195121951219513, 'provided': 0.024390243902439025, 'technique': 0.036585365853658534, 'C4.5': 0.012195121951219513, 'decision': 0.024390243902439025, 'trees': 0.024390243902439025, 'implicitly': 0.012195121951219513, 'determines': 0.024390243902439025, 'appropriate': 0.012195121951219513, 'created': 0.04878048780487805, 'predict': 0.012195121951219513, 'Virtually': 0.012195121951219513, 'Naive': 0.012195121951219513, 'Bayes': 0.024390243902439025, 'induction': 0.012195121951219513, 'GenEx': 0.012195121951219513, 'genetic': 0.024390243902439025, 'parameters': 0.036585365853658534, 'follows': 0.012195121951219513, 'series': 0.012195121951219513, 'heuristics': 0.024390243902439025, 'identify': 0.036585365853658534, 'optimizes': 0.012195121951219513, 'respect': 0.024390243902439025, 'performance': 0.024390243902439025, 'Unsupervised': 0.024390243902439025, 'approach': 0.06097560975609756, 'nice': 0.024390243902439025, 'properties': 0.024390243902439025, 'interpretable': 0.012195121951219513, 'rules': 0.012195121951219513, 'characterize': 0.024390243902439025, 'require': 0.012195121951219513, 'needed': 0.036585365853658534, 'Furthermore': 0.024390243902439025, 'tends': 0.012195121951219513, 'customize': 0.012195121951219513, 'resulting': 0.036585365853658534, 'necessarily': 0.024390243902439025, 'portable': 0.036585365853658534, 'demonstrate': 0.012195121951219513, 'angle': 0.012195121951219513, 'Instead': 0.012195121951219513, 'trying': 0.024390243902439025, 'explicit': 0.012195121951219513, 'algorithm[12': 0.012195121951219513, 'exploits': 0.012195121951219513, 'structure': 0.012195121951219513, 'central': 0.036585365853658534, 'selects': 0.012195121951219513, 'Web': 0.024390243902439025, 'pages': 0.024390243902439025, 'notion': 0.024390243902439025, 'prestige': 0.012195121951219513, 'recommendation': 0.012195121951219513, 'social': 0.012195121951219513, 'networks': 0.012195121951219513, 'previous': 0.012195121951219513, 'arbitrary': 0.036585365853658534, 'simply': 0.04878048780487805, 'intrinsic': 0.036585365853658534, 'easily': 0.036585365853658534, 'new': 0.036585365853658534, 'domains': 0.012195121951219513, 'languages': 0.012195121951219513, 'purpose': 0.024390243902439025, 'graph': 0.18292682926829268, 'ranking': 0.08536585365853659, 'NLP': 0.04878048780487805, 'Essentially': 0.012195121951219513, 'runs': 0.012195121951219513, 'specially': 0.012195121951219513, 'designed': 0.012195121951219513, 'particular': 0.024390243902439025, 'builds': 0.024390243902439025, 'vertices': 0.0975609756097561, 'Edges': 0.024390243902439025, 'measure': 0.06097560975609756, 'lexical': 0.012195121951219513, 'similarity': 0.10975609756097561, 'unit': 0.012195121951219513, 'Unlike': 0.012195121951219513, 'edges': 0.06097560975609756, 'typically': 0.04878048780487805, 'undirected': 0.012195121951219513, 'weighted': 0.012195121951219513, 'reflect': 0.012195121951219513, 'degree': 0.024390243902439025, 'constructed': 0.024390243902439025, 'form': 0.036585365853658534, 'stochastic': 0.012195121951219513, 'matrix': 0.024390243902439025, 'damping': 0.012195121951219513, 'factor': 0.024390243902439025, 'random': 0.08536585365853659, 'surfer': 0.012195121951219513, 'finding': 0.024390243902439025, 'eigenvector': 0.024390243902439025, 'corresponding': 0.024390243902439025, 'eigenvalue': 0.012195121951219513, '1': 0.012195121951219513, 'stationary': 0.04878048780487805, 'distribution': 0.024390243902439025, 'walk': 0.06097560975609756, 'correspond': 0.012195121951219513, 'rank': 0.07317073170731707, 'Potentially': 0.012195121951219513, 'similar': 0.14634146341463414, 'vertex': 0.036585365853658534, 'small': 0.012195121951219513, 'decide': 0.012195121951219513, 'individual': 0.036585365853658534, 'step': 0.08536585365853659, 'merges': 0.012195121951219513, 'ranked': 0.06097560975609756, 'adjacent': 0.024390243902439025, 'word': 0.06097560975609756, 'effect': 0.012195121951219513, 'allowing': 0.012195121951219513, 'advanced': 0.012195121951219513, 'ranks': 0.024390243902439025, 'look': 0.012195121951219513, 'consecutively': 0.012195121951219513, 'final': 0.04878048780487805, 'Note': 0.04878048780487805, 'placed': 0.036585365853658534, 'filtered': 0.012195121951219513, 'adjectives': 0.012195121951219513, 'nouns': 0.012195121951219513, 'best': 0.024390243902439025, 'linguistic': 0.012195121951219513, 'comes': 0.012195121951219513, 'play': 0.012195121951219513, 'co': 0.06097560975609756, 'connected': 0.036585365853658534, 'edge': 0.024390243902439025, 'window': 0.012195121951219513, 'size': 0.024390243902439025, 'N': 0.036585365853658534, '2–10': 0.012195121951219513, 'linked': 0.024390243902439025, 'Natural': 0.012195121951219513, 'string': 0.012195121951219513, 'cohesion': 0.012195121951219513, 'idea': 0.04878048780487805, 'near': 0.012195121951219513, 'meaningful': 0.012195121951219513, 'recommend': 0.024390243902439025, 'reader': 0.024390243902439025, 'method': 0.036585365853658534, 'limited': 0.012195121951219513, 'chosen': 0.012195121951219513, 'count': 0.036585365853658534, 'T': 0.06097560975609756, 'specified': 0.024390243902439025, 'fraction': 0.012195121951219513, 'total': 0.012195121951219513, 'selected': 0.024390243902439025, 'post-': 0.012195121951219513, 'merge': 0.012195121951219513, 'instances': 0.036585365853658534, 'result': 0.036585365853658534, 'potentially': 0.012195121951219513, 'produced': 0.012195121951219513, 'roughly': 0.012195121951219513, 'proportional': 0.012195121951219513, 'initially': 0.012195121951219513, 'clear': 0.012195121951219513, 'think': 0.012195121951219513, 'occurring': 0.012195121951219513, 'neighbors': 0.024390243902439025, 'occur': 0.024390243902439025, 'un': 0.012195121951219513, 'semi': 0.012195121951219513, 'hub': 0.012195121951219513, 'connects': 0.012195121951219513, 'modifying': 0.012195121951219513, 'Running': 0.012195121951219513, 'places': 0.012195121951219513, 'importance': 0.07317073170731707, 'contribute': 0.012195121951219513, 'ends': 0.012195121951219513, 'probably': 0.024390243902439025, 'contain': 0.036585365853658534, 'densely': 0.024390243902439025, 'regions': 0.012195121951219513, 'contexts': 0.012195121951219513, 'assigns': 0.012195121951219513, 'centers': 0.012195121951219513, 'clusters': 0.012195121951219513, 'getting': 0.024390243902439025, 'considered': 0.04878048780487805, 'Document': 0.036585365853658534, 'Like': 0.012195121951219513, 'aims': 0.012195121951219513, 'essence': 0.012195121951219513, 'real': 0.024390243902439025, 'difference': 0.012195121951219513, 'dealing': 0.012195121951219513, '—': 0.024390243902439025, 'instead': 0.012195121951219513, 'details': 0.012195121951219513, 'mention': 0.012195121951219513, 'common': 0.036585365853658534, 'ROUGE': 0.07317073170731707, 'Oriented': 0.024390243902439025, 'Understudy': 0.024390243902439025, 'Gisting': 0.024390243902439025, 'Evaluation': 0.04878048780487805, 'covers': 0.012195121951219513, 'present': 0.024390243902439025, 'references': 0.024390243902439025, 'encourage': 0.012195121951219513, 'computed': 0.024390243902439025, '4-gram': 0.012195121951219513, 'matching': 0.012195121951219513, 'ROUGE-1': 0.036585365853658534, 'division': 0.012195121951219513, 'reference': 0.06097560975609756, 'averaged': 0.012195121951219513, 'overlap': 0.04878048780487805, 'concepts': 0.04878048780487805, 'coherent': 0.012195121951219513, 'flow': 0.012195121951219513, 'sensible': 0.012195121951219513, 'High': 0.012195121951219513, 'order': 0.036585365853658534, 'n': 0.024390243902439025, 'gram': 0.024390243902439025, 'judge': 0.012195121951219513, 'fluency': 0.012195121951219513, 'BLEU': 0.024390243902439025, 'precision-': 0.012195121951219513, 'favor': 0.012195121951219513, 'accuracy': 0.012195121951219513, 'promising': 0.012195121951219513, 'line': 0.012195121951219513, 'adaptive': 0.036585365853658534, 'summarization.[13': 0.012195121951219513, 'preliminary': 0.012195121951219513, 'recognition': 0.012195121951219513, 'genre': 0.024390243902439025, 'subsequent': 0.012195121951219513, 'optimized': 0.012195121951219513, 'perform': 0.024390243902439025, 'created.[14': 0.012195121951219513, 'Basically': 0.012195121951219513, 'good': 0.036585365853658534, 'Features': 0.012195121951219513, 'sentence': 0.17073170731707318, 'main': 0.036585365853658534, 'difficulty': 0.012195121951219513, 'extracting': 0.012195121951219513, 'people': 0.012195121951219513, 'abstracts': 0.012195121951219513, 'usually': 0.012195121951219513, 'sufficient': 0.012195121951219513, 'evaluation': 0.12195121951219512, 'purposes': 0.012195121951219513, 'cares': 0.012195121951219513, 'Maximum': 0.036585365853658534, 'entropy': 0.036585365853658534, 'DUC': 0.024390243902439025, '2001': 0.012195121951219513, '2002': 0.012195121951219513, 'workshops': 0.012195121951219513, 'TNO': 0.012195121951219513, 'developed': 0.04878048780487805, 'hybrid': 0.012195121951219513, 'naive': 0.012195121951219513, 'statistical': 0.024390243902439025, 'models': 0.10975609756097561, 'modeling': 0.024390243902439025, 'salience': 0.012195121951219513, 'exhibited': 0.012195121951219513, 'wanted': 0.012195121951219513, 'explore': 0.012195121951219513, 'effectiveness': 0.012195121951219513, 'maximum': 0.012195121951219513, 'meeting': 0.012195121951219513, 'robust': 0.012195121951219513, 'feature': 0.012195121951219513, 'dependencies': 0.012195121951219513, 'successfully': 0.024390243902439025, 'broadcast': 0.012195121951219513, 'LexRank': 0.12195121951219512, 'spirit': 0.012195121951219513, 'gets': 0.012195121951219513, 'issue': 0.024390243902439025, 'costly': 0.012195121951219513, 'centroid': 0.024390243902439025, 'vector': 0.012195121951219513, 'regard': 0.024390243902439025, 'principled': 0.012195121951219513, 'estimate': 0.012195121951219513, 'walks': 0.024390243902439025, 'centrality': 0.024390243902439025, 'LexRank[15': 0.012195121951219513, 'essentially': 0.024390243902439025, 'identical': 0.012195121951219513, 'groups': 0.024390243902439025, 'time': 0.04878048780487805, 'focused': 0.012195121951219513, 'creating': 0.012195121951219513, 'cosine': 0.024390243902439025, 'TF': 0.012195121951219513, 'IDF': 0.012195121951219513, 'vectors': 0.012195121951219513, 'normalized': 0.012195121951219513, 'lengths': 0.012195121951219513, 'explored': 0.012195121951219513, 'unweighted': 0.012195121951219513, 'values': 0.012195121951219513, 'experimented': 0.012195121951219513, 'weights': 0.036585365853658534, 'equal': 0.012195121951219513, 'continuous': 0.012195121951219513, 'formed': 0.012195121951219513, 'combining': 0.012195121951219513, 'cutoff': 0.012195121951219513, 'worth': 0.012195121951219513, 'noting': 0.012195121951219513, 'described': 0.024390243902439025, 'MEAD': 0.012195121951219513, 'combines': 0.012195121951219513, 'linear': 0.012195121951219513, 'combination': 0.012195121951219513, 'tuned': 0.012195121951219513, 'additional': 0.012195121951219513, 'absolutely': 0.012195121951219513, 'necessary': 0.012195121951219513, 'distinction': 0.012195121951219513, 'remains': 0.024390243902439025, 'choose': 0.012195121951219513, 'grown': 0.012195121951219513, 'greater': 0.012195121951219513, 'risk': 0.012195121951219513, 'duplicate': 0.012195121951219513, 'place': 0.012195121951219513, 'event': 0.012195121951219513, 'distinct': 0.012195121951219513, 'ideas': 0.024390243902439025, 'address': 0.012195121951219513, 'applies': 0.024390243902439025, 'heuristic': 0.024390243902439025, 'adding': 0.024390243902439025, 'discards': 0.012195121951219513, 'ones': 0.024390243902439025, 'Cross': 0.012195121951219513, 'Sentence': 0.012195121951219513, 'Information': 0.012195121951219513, 'Subsumption': 0.012195121951219513, 'CSIS': 0.024390243902439025, 'great': 0.012195121951219513, 'stems': 0.012195121951219513, 'recommending': 0.012195121951219513, 'turn': 0.012195121951219513, 'intuitive': 0.012195121951219513, 'sense': 0.012195121951219513, 'allows': 0.024390243902439025, 'independent': 0.036585365853658534, 'imagine': 0.012195121951219513, 'indicating': 0.012195121951219513, 'vary': 0.012195121951219513, 'considerably': 0.012195121951219513, 'biomedical': 0.012195121951219513, 'recommendation\"-based': 0.012195121951219513, 'Multi': 0.07317073170731707, 'Main': 0.012195121951219513, 'procedure': 0.024390243902439025, 'texts': 0.024390243902439025, 'written': 0.024390243902439025, 'Resulting': 0.012195121951219513, 'report': 0.012195121951219513, 'users': 0.012195121951219513, 'professional': 0.012195121951219513, 'consumers': 0.012195121951219513, 'quickly': 0.012195121951219513, 'familiarize': 0.012195121951219513, 'contained': 0.012195121951219513, 'complementing': 0.012195121951219513, 'aggregators': 0.012195121951219513, 'performing': 0.012195121951219513, 'road': 0.012195121951219513, 'coping': 0.012195121951219513, 'overload': 0.012195121951219513, 'response': 0.012195121951219513, 'question.[16][8': 0.012195121951219513, 'reports': 0.012195121951219513, 'concise': 0.012195121951219513, 'comprehensive': 0.024390243902439025, 'opinions': 0.012195121951219513, 'outlined': 0.012195121951219513, 'perspectives': 0.012195121951219513, 'goal': 0.012195121951219513, 'brief': 0.012195121951219513, 'simplify': 0.012195121951219513, 'cut': 0.012195121951219513, 'pointing': 0.012195121951219513, 'required': 0.024390243902439025, 'limiting': 0.012195121951219513, 'accessing': 0.012195121951219513, 'files': 0.012195121951219513, 'refinement': 0.012195121951219513, 'Automatic': 0.012195121951219513, 'sources': 0.024390243902439025, 'algorithmically': 0.012195121951219513, 'editorial': 0.012195121951219513, 'touch': 0.012195121951219513, 'subjective': 0.012195121951219513, 'making': 0.024390243902439025, 'completely': 0.012195121951219513, 'unbiased.[dubious': 0.012195121951219513, '–': 0.024390243902439025, 'discuss': 0.012195121951219513, 'Incorporating': 0.012195121951219513, 'faces': 0.012195121951219513, 'potential': 0.012195121951219513, 'redundancy': 0.036585365853658534, 'diverse': 0.012195121951219513, 'differ': 0.012195121951219513, 'deals': 0.012195121951219513, 'stage': 0.012195121951219513, 'Maximal': 0.012195121951219513, 'Marginal': 0.024390243902439025, 'Relevance': 0.024390243902439025, 'MMR),[17': 0.012195121951219513, 'eliminate': 0.012195121951219513, 'Page': 0.012195121951219513, 'Lex': 0.012195121951219513, 'handles': 0.012195121951219513, 'unified': 0.012195121951219513, 'mathematical': 0.012195121951219513, 'framework': 0.012195121951219513, 'absorbing': 0.036585365853658534, 'Markov': 0.012195121951219513, 'chain': 0.012195121951219513, 'standard': 0.012195121951219513, 'states': 0.024390243902439025, 'act': 0.012195121951219513, 'black': 0.012195121951219513, 'holes': 0.012195121951219513, 'cause': 0.012195121951219513, 'abruptly': 0.012195121951219513, 'state': 0.06097560975609756, 'GRASSHOPPER.[18': 0.012195121951219513, 'addition': 0.012195121951219513, 'explicitly': 0.012195121951219513, 'promoting': 0.012195121951219513, 'GRASSHOPPER': 0.012195121951219513, 'incorporates': 0.012195121951219513, 'prior': 0.012195121951219513, 'art': 0.04878048780487805, 'mixtures': 0.024390243902439025, 'submodular': 0.24390243902439024, 'functions': 0.15853658536585366, 'achieved': 0.036585365853658534, 'Corpora': 0.012195121951219513, '04': 0.012195121951219513, '07.[19': 0.012195121951219513, 'Similar': 0.012195121951219513, 'determinantal': 0.024390243902439025, 'DUC-04.[20': 0.012195121951219513, 'lingual': 0.012195121951219513, 'avoids': 0.012195121951219513, 'works': 0.024390243902439025, 'simplifying': 0.012195121951219513, 'ideograms': 0.036585365853658534, 'represent': 0.024390243902439025, 'meaning': 0.024390243902439025, 'evaluates': 0.012195121951219513, 'qualitatively': 0.024390243902439025, 'comparing': 0.012195121951219513, 'shape': 0.012195121951219513, 'said': 0.012195121951219513, 'recently': 0.024390243902439025, 'tool': 0.024390243902439025, 'frequency': 0.036585365853658534, 'preprocessing': 0.012195121951219513, 'kind': 0.012195121951219513, 'supplied': 0.012195121951219513, 'equivalence': 0.012195121951219513, 'equivalent': 0.012195121951219513, 'desired': 0.012195121951219513, 'tools': 0.012195121951219513, 'emerged': 0.012195121951219513, 'powerful': 0.024390243902439025, 'combinatorial': 0.012195121951219513, 'optimization': 0.07317073170731707, 'subset': 0.012195121951219513, 'facility': 0.012195121951219513, 'location': 0.012195121951219513, 'Facility': 0.012195121951219513, 'Location': 0.012195121951219513, 'seen': 0.012195121951219513, 'encouraging': 0.012195121951219513, 'efficiently': 0.012195121951219513, 'combine': 0.012195121951219513, 'supervision': 0.012195121951219513, 'right': 0.024390243902439025, 'fitting': 0.012195121951219513, 'admit': 0.012195121951219513, 'efficient': 0.012195121951219513, 'simple': 0.024390243902439025, 'greedy': 0.024390243902439025, 'admits': 0.012195121951219513, 'constant': 0.012195121951219513, 'guarantee.[21': 0.012195121951219513, 'extremely': 0.012195121951219513, 'implement': 0.012195121951219513, 'scale': 0.012195121951219513, 'datasets': 0.012195121951219513, 'Lin': 0.024390243902439025, 'Bilmes': 0.024390243902439025, '2012[22': 0.012195121951219513, 'shows': 0.024390243902439025, 'achieve': 0.024390243902439025, 'date': 0.012195121951219513, 'DUC-04': 0.012195121951219513, 'DUC-05': 0.012195121951219513, 'DUC-06': 0.012195121951219513, 'DUC-07': 0.012195121951219513, '2011,[23': 0.012195121951219513, 'breakthrough': 0.012195121951219513, 'establishing': 0.012195121951219513, 'problems.[citation': 0.012195121951219513, 'Functions': 0.024390243902439025, 'Tschiatschek': 0.024390243902439025, 'et': 0.036585365853658534, 'al': 0.036585365853658534, '2014': 0.012195121951219513, 'show[24': 0.012195121951219513, 'Bairi': 0.012195121951219513, '2015[25': 0.012195121951219513, 'utility': 0.012195121951219513, 'hierarchies': 0.012195121951219513, 'datasets.[26': 0.012195121951219513, 'icon': 0.012195121951219513, '\\t\\n': 0.012195121951219513, 'expansion': 0.012195121951219513, 'help': 0.012195121951219513, 'February': 0.012195121951219513, '2017': 0.012195121951219513, 'Specific': 0.012195121951219513, 'Reddit': 0.012195121951219513, 'bot': 0.012195121951219513, 'autotldr\",[27': 0.012195121951219513, '2011': 0.012195121951219513, 'comment': 0.012195121951219513, 'reddit': 0.024390243902439025, 'posts': 0.012195121951219513, 'community': 0.012195121951219513, 'upvoted': 0.012195121951219513, 'hundreds': 0.012195121951219513, 'thousands': 0.012195121951219513, 'times.[28': 0.012195121951219513, 'TL;DR': 0.012195121951219513, '−': 0.012195121951219513, 'Internet': 0.012195121951219513, 'slang': 0.012195121951219513, 'read\".[29][30': 0.012195121951219513, 'evaluate': 0.012195121951219513, 'informativeness': 0.024390243902439025, 'compare': 0.024390243902439025, 'fall': 0.012195121951219513, 'extrinsic,[31': 0.012195121951219513, 'inter': 0.024390243902439025, 'textual': 0.06097560975609756, 'intra': 0.024390243902439025, 'textual.[32': 0.012195121951219513, 'Intrinsic': 0.024390243902439025, 'extrinsic': 0.024390243902439025, 'tests': 0.024390243902439025, 'affects': 0.012195121951219513, 'completion': 0.012195121951219513, 'evaluations': 0.024390243902439025, 'assessed': 0.012195121951219513, 'coherence': 0.036585365853658534, 'Extrinsic': 0.012195121951219513, 'hand': 0.012195121951219513, 'tested': 0.012195121951219513, 'impact': 0.012195121951219513, 'assessment': 0.012195121951219513, 'reading': 0.012195121951219513, 'comprehension': 0.012195121951219513, 'Inter': 0.012195121951219513, 'Intra': 0.012195121951219513, 'assess': 0.012195121951219513, 'focus': 0.024390243902439025, 'contrastive': 0.012195121951219513, 'analysis': 0.024390243902439025, 'outputs': 0.012195121951219513, 'judgement': 0.012195121951219513, 'wide': 0.012195121951219513, 'variance': 0.012195121951219513, 'means': 0.012195121951219513, 'particularly': 0.012195121951219513, 'Manual': 0.012195121951219513, 'labor': 0.012195121951219513, 'intensive': 0.012195121951219513, 'humans': 0.012195121951219513, 'issues': 0.012195121951219513, 'concerning': 0.012195121951219513, 'metrics': 0.036585365853658534, 'NIST': 0.012195121951219513, 'annual': 0.012195121951219513, 'Understanding': 0.012195121951219513, 'Conferences': 0.012195121951219513, 'submit': 0.012195121951219513, 'metric': 0.012195121951219513, '2': 0.012195121951219513, 'calculates': 0.012195121951219513, 'overlaps': 0.012195121951219513, 'previously': 0.012195121951219513, 'indicate': 0.012195121951219513, 'shared': 0.012195121951219513, 'unable': 0.012195121951219513, 'feedback': 0.012195121951219513, 'Anaphor': 0.012195121951219513, 'resolution': 0.012195121951219513, 'fully': 0.012195121951219513, 'solved': 0.012195121951219513, 'Visual': 0.012195121951219513, 'judges': 0.012195121951219513, 'summarization.[33': 0.012195121951219513, 'Domain': 0.024390243902439025, 'versus': 0.012195121951219513, 'rich': 0.012195121951219513, 'Recent': 0.024390243902439025, 'drifted': 0.012195121951219513, 'utilize': 0.024390243902439025, 'medical': 0.024390243902439025, 'codified': 0.012195121951219513, 'ontologies.[34': 0.012195121951219513, 'Evaluating': 0.012195121951219513, 'drawback': 0.012195121951219513, 'far': 0.012195121951219513, 'hard': 0.012195121951219513, 'expensive': 0.012195121951219513, 'comparison': 0.012195121951219513, 'manual': 0.012195121951219513, 'annotation': 0.012195121951219513, 'performed': 0.012195121951219513, 'SCU': 0.012195121951219513, 'Pyramid': 0.012195121951219513, 'Method': 0.012195121951219513, 'input': 0.012195121951219513, 'serve': 0.012195121951219513, 'gold': 0.012195121951219513, 'standards': 0.012195121951219513, 'quantitative': 0.012195121951219513, 'History': 0.012195121951219513, 'publication': 0.012195121951219513, 'area': 0.012195121951219513, 'dates': 0.012195121951219513, '1957': 0.012195121951219513, '35': 0.012195121951219513, 'Hans': 0.012195121951219513, 'Peter': 0.012195121951219513, 'Luhn': 0.012195121951219513, 'starting': 0.012195121951219513, 'Research': 0.012195121951219513, 'increased': 0.012195121951219513, 'significantly': 0.012195121951219513, '2015': 0.012195121951219513, 'Term': 0.012195121951219513, 'inverse': 0.012195121951219513, '2016': 0.024390243902439025, 'Pattern': 0.012195121951219513, 'option': 0.012195121951219513, 'surpassed': 0.012195121951219513, 'latent': 0.012195121951219513, 'LSA': 0.012195121951219513, 'non': 0.012195121951219513, 'factorization': 0.012195121951219513, 'NMF': 0.012195121951219513, 'replace': 0.012195121951219513, '2019': 0.012195121951219513, 'dominated': 0.012195121951219513, 'nearing': 0.012195121951219513, 'maturity': 0.012195121951219513, '2020': 0.012195121951219513, 'active': 0.012195121951219513, 'shifting': 0.012195121951219513, 'summation': 0.012195121951219513, 'summarization.[36': 0.012195121951219513, 'Recently': 0.012195121951219513, 'rise': 0.012195121951219513, 'Transformer': 0.012195121951219513, 'replacing': 0.012195121951219513, 'traditional': 0.012195121951219513, 'RNN': 0.012195121951219513, 'LSTM': 0.012195121951219513, 'flexibility': 0.012195121951219513, 'mapping': 0.012195121951219513, 'type': 0.012195121951219513, 'suited': 0.012195121951219513, 'includes': 0.012195121951219513, 'T5[37': 0.012195121951219513, 'Pegasus': 0.012195121951219513}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = [sent for sent in doc.sents]\n",
        "print(sent_tokens[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wByJZdJPW_Fy",
        "outputId": "44f2e39a-0792-41d6-97fc-f77de8316b11"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ Commercial products\n",
            ", In 2022 Google Docs released an automatic summarization feature.[6]\n",
            "\n",
            ", Approaches\n",
            ", There are two general approaches to automatic summarization: extraction and abstraction.\n",
            "\n",
            ", Extraction-based summarization\n",
            ", Here, content is extracted from the original data, but the extracted content is not modified in any way., Examples of extracted content include key-phrases that can be used to \"tag\" or index a text document, or key sentences (including headings) that collectively comprise an abstract, and representative images or video segments, as stated above., For text, extraction is analogous to the process of skimming, where the summary (if available), headings and subheadings, figures, the first and last paragraphs of a section, and optionally the first and last sentences in a paragraph are read before one chooses to read the entire document in detail.[7], Other examples of extraction that include key sequences of text in terms of clinical relevance (including patient/problem, intervention, and outcome).[8]\n",
            "\n",
            "Abstraction-based summarization\n",
            ", This has been applied mainly for text., Abstractive methods build an internal semantic representation of the original content, and then use this representation to create a summary that is closer to what a human might express., Abstraction may transform the extracted content by paraphrasing sections of the source document, to condense a text more strongly than extraction., Such transformation, however, is computationally much more challenging than extraction, involving both natural language processing and often a deep understanding of the domain of the original text in cases where the original document relates to a special field of knowledge., \"Paraphrasing\" is even more difficult to apply to image and video, which is why most summarization systems are extractive.\n",
            "\n",
            ", Aided summarization\n",
            ", Approaches aimed at higher summarization quality rely on combined software and human effort., In Machine Aided Human Summarization, extractive techniques highlight candidate passages for inclusion (to which the human adds or removes text)., In Human Aided Machine Summarization, a human post-processes software output, in the same way that one edits the output of automatic translation by Google Translate.\n",
            "\n",
            ", Applications and systems for summarization\n",
            ", There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mUMTii5FXWrU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}